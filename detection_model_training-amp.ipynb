{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "architectural-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil\n",
    "from utils import helper\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torchinfo import summary\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "supported-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "# Columns: image_path, label_path, bboxes, classes\n",
    "impath = 'data/kitti/integration/resized/training/images/'\n",
    "labels_path = 'data/kitti/integration/resized/training/labels/'\n",
    "imlabel_list = helper.imlabel(impath, labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alert-kidney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/kitti/integration/resized/training/images/000000_resized.jpg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imlabel_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "laden-ancient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_path</th>\n",
       "      <th>class</th>\n",
       "      <th>bboxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>Pedestrian</td>\n",
       "      <td>[1047.4205405405405, 112.15686274509804, 1191....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>Truck</td>\n",
       "      <td>[869.5441066666667, 120.88888888888889, 913.55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>Car</td>\n",
       "      <td>[562.32192, 140.3207729468599, 614.80704, 157....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>Cyclist</td>\n",
       "      <td>[981.5210666666668, 126.72463768115941, 999.48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>DontCare</td>\n",
       "      <td>[730.9764266666667, 131.17681159420292, 856.77...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path                                         label_path       class                                             bboxes\n",
       "0  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...  Pedestrian  [1047.4205405405405, 112.15686274509804, 1191....\n",
       "1  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...       Truck  [869.5441066666667, 120.88888888888889, 913.55...\n",
       "2  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...         Car  [562.32192, 140.3207729468599, 614.80704, 157....\n",
       "3  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...     Cyclist  [981.5210666666668, 126.72463768115941, 999.48...\n",
       "4  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...    DontCare  [730.9764266666667, 131.17681159420292, 856.77..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['image_path','label_path','class','bboxes'])\n",
    "# df = pd.DataFrame()\n",
    "# df['image_path'] = imlabel_list[:][0]\n",
    "# df['label_path'] = imlabel_list[:][1]\n",
    "# df.head()\n",
    "\n",
    "for item in imlabel_list:\n",
    "    #bboxes = helper.fetch_bboxes(item[1]).tolist()\n",
    "    bboxes = helper.fetch_bboxes(item[1])\n",
    "    classes = helper.fetch_classes(item[1])\n",
    "    for i,cls_bbox in enumerate(zip(classes,bboxes)):\n",
    "        # print(cls_bbox)\n",
    "        #df.loc[i,'image_path'] = item[0]\n",
    "        #df.loc[i,'label_path'] = item[1]\n",
    "        #df.loc[i,'class'] = cls_bbox[0]\n",
    "        \n",
    "        #df.loc[i,'bboxes'] = cls_bbox[1]\n",
    "        # df = df.append([item[0],item[1],cls_bbox[0],cls_bbox[1]])\n",
    "        df = df.append({'image_path':item[0], 'label_path': item[1],\n",
    "                        'class': cls_bbox[0], 'bboxes': cls_bbox[1][:4]}, ignore_index=True)\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "monthly-society",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Car               42505\n",
       "DontCare          17015\n",
       "Pedestrian         6686\n",
       "Van                4283\n",
       "Cyclist            2424\n",
       "Truck              1614\n",
       "Misc               1394\n",
       "Tram                743\n",
       "Person_sitting      304\n",
       "2-wheeler           122\n",
       "pedestrian           70\n",
       "car                  50\n",
       "dontcare              1\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "commercial-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove classes that we don't need\n",
    "\n",
    "remove_classes = ['Truck', 'Misc', 'Tram']\n",
    "\n",
    "for item in remove_classes:\n",
    "    df.drop(df[df['class'] == item].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bright-notion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_path</th>\n",
       "      <th>class</th>\n",
       "      <th>bboxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>Pedestrian</td>\n",
       "      <td>[1047.4205405405405, 112.15686274509804, 1191....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>Car</td>\n",
       "      <td>[562.32192, 140.3207729468599, 614.80704, 157....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>Cyclist</td>\n",
       "      <td>[981.5210666666668, 126.72463768115941, 999.48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>DontCare</td>\n",
       "      <td>[730.9764266666667, 131.17681159420292, 856.77...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>DontCare</td>\n",
       "      <td>[741.7984000000001, 135.23478260869567, 765.67...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path                                         label_path       class                                             bboxes\n",
       "0  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...  Pedestrian  [1047.4205405405405, 112.15686274509804, 1191....\n",
       "2  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...         Car  [562.32192, 140.3207729468599, 614.80704, 157....\n",
       "3  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...     Cyclist  [981.5210666666668, 126.72463768115941, 999.48...\n",
       "4  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...    DontCare  [730.9764266666667, 131.17681159420292, 856.77...\n",
       "5  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...    DontCare  [741.7984000000001, 135.23478260869567, 765.67..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unlikely-notion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_path</th>\n",
       "      <th>class</th>\n",
       "      <th>bboxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>pedestrian</td>\n",
       "      <td>[1047.4205405405405, 112.15686274509804, 1191....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>car</td>\n",
       "      <td>[562.32192, 140.3207729468599, 614.80704, 157....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>2-wheeler</td>\n",
       "      <td>[981.5210666666668, 126.72463768115941, 999.48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>dontcare</td>\n",
       "      <td>[730.9764266666667, 131.17681159420292, 856.77...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>dontcare</td>\n",
       "      <td>[741.7984000000001, 135.23478260869567, 765.67...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path                                         label_path       class                                             bboxes\n",
       "0  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...  pedestrian  [1047.4205405405405, 112.15686274509804, 1191....\n",
       "2  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...         car  [562.32192, 140.3207729468599, 614.80704, 157....\n",
       "3  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...   2-wheeler  [981.5210666666668, 126.72463768115941, 999.48...\n",
       "4  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...    dontcare  [730.9764266666667, 131.17681159420292, 856.77...\n",
       "5  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...    dontcare  [741.7984000000001, 135.23478260869567, 765.67..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clubbing similar categories\n",
    "class_dict = {'Car': 'car','car':'car', \n",
    "              'Pedestrian': 'pedestrian','pedestrian': 'pedestrian',\n",
    "              '2-wheeler':'2-wheeler', 'Van': 'car', 'dontcare': 'dontcare', \n",
    "              'Cyclist': '2-wheeler', 'Person_sitting' : 'pedestrian', 'DontCare' : 'dontcare'}\n",
    "\n",
    "df['class'] = df['class'].apply(lambda x:  class_dict[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "compatible-universal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car           46838\n",
       "dontcare      17016\n",
       "pedestrian     7060\n",
       "2-wheeler      2546\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bright-racing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_path</th>\n",
       "      <th>class</th>\n",
       "      <th>bboxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1047.4205405405405, 112.15686274509804, 1191....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>2</td>\n",
       "      <td>[562.32192, 140.3207729468599, 614.80704, 157....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>0</td>\n",
       "      <td>[981.5210666666668, 126.72463768115941, 999.48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>3</td>\n",
       "      <td>[730.9764266666667, 131.17681159420292, 856.77...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/kitti/integration/resized/training/images...</td>\n",
       "      <td>data/kitti/integration/resized/training/labels...</td>\n",
       "      <td>3</td>\n",
       "      <td>[741.7984000000001, 135.23478260869567, 765.67...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path                                         label_path  class                                             bboxes\n",
       "0  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...      1  [1047.4205405405405, 112.15686274509804, 1191....\n",
       "2  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...      2  [562.32192, 140.3207729468599, 614.80704, 157....\n",
       "3  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...      0  [981.5210666666668, 126.72463768115941, 999.48...\n",
       "4  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...      3  [730.9764266666667, 131.17681159420292, 856.77...\n",
       "5  data/kitti/integration/resized/training/images...  data/kitti/integration/resized/training/labels...      3  [741.7984000000001, 135.23478260869567, 765.67..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = {'2-wheeler': 0, \n",
    "              'pedestrian': 1, 'car': 2,\n",
    "              'dontcare': 3}\n",
    "\n",
    "df['class'] = df['class'].apply(lambda x:  class_dict[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "warming-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset Split\n",
    "X = df.image_path\n",
    "y = df[['bboxes', 'class']]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "imported-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(im_arr):\n",
    "    # Normalizes image with imagenet stats.\"\"\"\n",
    "    imagenet_stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n",
    "    return (im_arr - imagenet_stats[0])/imagenet_stats[1]\n",
    "\n",
    "class KittiDS(Dataset):\n",
    "    def __init__(self, paths, bboxes, y):\n",
    "        # self.transforms = transforms\n",
    "        self.paths = paths.values\n",
    "        self.bboxes = bboxes.values\n",
    "        self.y = y.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        y_class = self.y[idx]\n",
    "        y_bbox = self.bboxes[idx]\n",
    "        # x, y_bb = transformsXY(path, self.bb[idx], self.transforms)\n",
    "        x = cv2.cvtColor(cv2.imread(path).astype('float32'),\n",
    "                         cv2.COLOR_BGR2RGB)/255\n",
    "        x = normalize(x)\n",
    "        x = np.rollaxis(x, 2)\n",
    "        return x, y_bbox, y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ethical-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_kitti = KittiDS(X_train, y_train['bboxes'], y_train['class'])\n",
    "#val_kitti = KittiDS(X_val, y_val['bboxes'], y_val['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beginning-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch size\n",
    "#batch_size = 16\n",
    "# For autobatching and parallelizing data-loading\n",
    "#train_kitti_pt = DataLoader(train_kitti, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "#val_kitti_pt = DataLoader(val_kitti, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "elect-picture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flexing my GPU ^_^ :  GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "# verify if GPU is being used with its name\n",
    "print(\"Flexing my GPU ^_^ : \", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "deluxe-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "french-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "practical-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyKitti_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PyKitti_model, self).__init__()\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "        # children returns immediate child modules\n",
    "        layers = list(resnet.children())[:8]\n",
    "        self.features1 = nn.Sequential(*layers[:6])\n",
    "        self.features2 = nn.Sequential(*layers[6:])\n",
    "        # classification network\n",
    "        self.classifier = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n",
    "        # bbox regressor network\n",
    "        self.bbox = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features1(x)\n",
    "        # print(\"x shape after extracting features1: \", x.shape)\n",
    "        x = self.features2(x)\n",
    "        # print(\"x shape after extracting features2: \", x.shape)\n",
    "        x = F.relu(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
    "        # print(\"x shape before reshape: \", x.shape)\n",
    "        # reshape tensor\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        return self.classifier(x), self.bbox(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fiscal-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "def train(model, optimizer, train_kitti_pt, val_kitti_pt, epochs=10,C=1000):\n",
    "    for i in range(epochs):\n",
    "        # enables model training, grad compute\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        correct = 0\n",
    "        for x, y_bbox, y_class in train_kitti_pt:\n",
    "            batch = y_class.shape[0]\n",
    "            # fp32 precision\n",
    "            # x = x.cuda().float()\n",
    "            # x = x.float().to(device, dtype=float)\n",
    "            x = x.float().to(device)\n",
    "            # x = x.to(device, dtype=torch.float16)\n",
    "            # print(\"x shape: \", x.shape)\n",
    "            # y_class = y_class.cuda()\n",
    "            y_class = y_class.long().to(device)\n",
    "            # print(\"y_class: \", y_class, 'y_class shape: ', y_class.shape)\n",
    "            # fp32 precision \n",
    "            # y_bbox = y_bbox.float().to(device, dtype=float)\n",
    "            y_bbox = y_bbox.float().to(device)\n",
    "            # y_bbox = y_bbox.to(device, dtype=torch.float16)\n",
    "            # print(\"y_bbox: \", y_bbox, \"\\ny_bbox shape\", y_bbox.shape)\n",
    "            out_class, out_bbox = model.forward(x)\n",
    "            # print(\"out_bbox: \", out_bbox, \"\\nout_bbox shape\", out_bbox.shape)\n",
    "            # print(\"out_class: \", out_class, '\\nout_class shape: ', out_class.shape)\n",
    "            # compute classification loss: torch.max(outputs, 1)[1], torch.max(labels, 1)[1]\n",
    "            clf_loss = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "            # compute L1 loss\n",
    "            bbox_reg_loss = F.l1_loss(out_bbox, y_bbox, reduction=\"none\").sum(1)\n",
    "            bbox_reg_loss = bbox_reg_loss.sum()\n",
    "            # computing total loss\n",
    "            loss = clf_loss + bbox_reg_loss/C\n",
    "            # set gradients to 0\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total += batch\n",
    "            sum_loss += loss.item()\n",
    "            _, pred = torch.max(out_class, 1)\n",
    "            correct += pred.eq(y_class).sum().item()\n",
    "        train_loss = sum_loss/total\n",
    "        train_acc = correct/total\n",
    "        val_loss, val_acc = val_metrics(model, val_kitti_pt, C)\n",
    "        print(\"Epoch: \",i+1,\"/\",epochs,\"\\n----------------------------\")\n",
    "        print(\"Train_loss: %.3f, Train_acc: %.3f,\\nVal_loss: %.3f, Val_acc: %.3f\" % \n",
    "              (train_loss, train_acc,val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "rough-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute validation metrics\n",
    "def val_metrics(model, val_kitti_pt, C=1000):\n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    # pair .eval() with no_grad\n",
    "    # turn off grad computation\n",
    "    with torch.no_grad():\n",
    "        for x, y_bbox, y_class in val_kitti_pt:\n",
    "            batch = y_class.shape[0]\n",
    "            # x = x.float().to(device, dtype=float)\n",
    "            x = x.float().to(device)\n",
    "            y_class = y_class.long().to(device)\n",
    "            y_bbox = y_bbox.float().to(device)\n",
    "            out_class, out_bbox = model.forward(x)\n",
    "            clf_loss = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "            bbox_reg_loss = F.l1_loss(out_bbox, y_bbox, reduction=\"none\").sum(1)\n",
    "            bbox_reg_loss = bbox_reg_loss.sum()\n",
    "            loss = clf_loss + bbox_reg_loss/C\n",
    "            _, pred = torch.max(out_class, 1)\n",
    "            correct += pred.eq(y_class).sum().item()\n",
    "            sum_loss += loss.item()\n",
    "            total += batch\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "attractive-spider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "PyKitti_model                                 --                        --\n",
       "├─Sequential: 1-1                             [16, 128, 68, 120]        --\n",
       "│    └─Conv2d: 2-1                            [16, 64, 272, 480]        9,408\n",
       "│    └─BatchNorm2d: 2-2                       [16, 64, 272, 480]        128\n",
       "│    └─ReLU: 2-3                              [16, 64, 272, 480]        --\n",
       "│    └─MaxPool2d: 2-4                         [16, 64, 136, 240]        --\n",
       "│    └─Sequential: 2-5                        [16, 64, 136, 240]        --\n",
       "│    │    └─BasicBlock: 3-1                   [16, 64, 136, 240]        73,984\n",
       "│    │    └─BasicBlock: 3-2                   [16, 64, 136, 240]        73,984\n",
       "│    │    └─BasicBlock: 3-3                   [16, 64, 136, 240]        73,984\n",
       "│    └─Sequential: 2-6                        [16, 128, 68, 120]        --\n",
       "│    │    └─BasicBlock: 3-4                   [16, 128, 68, 120]        230,144\n",
       "│    │    └─BasicBlock: 3-5                   [16, 128, 68, 120]        295,424\n",
       "│    │    └─BasicBlock: 3-6                   [16, 128, 68, 120]        295,424\n",
       "│    │    └─BasicBlock: 3-7                   [16, 128, 68, 120]        295,424\n",
       "├─Sequential: 1-2                             [16, 512, 17, 30]         --\n",
       "│    └─Sequential: 2-7                        [16, 256, 34, 60]         --\n",
       "│    │    └─BasicBlock: 3-8                   [16, 256, 34, 60]         919,040\n",
       "│    │    └─BasicBlock: 3-9                   [16, 256, 34, 60]         1,180,672\n",
       "│    │    └─BasicBlock: 3-10                  [16, 256, 34, 60]         1,180,672\n",
       "│    │    └─BasicBlock: 3-11                  [16, 256, 34, 60]         1,180,672\n",
       "│    │    └─BasicBlock: 3-12                  [16, 256, 34, 60]         1,180,672\n",
       "│    │    └─BasicBlock: 3-13                  [16, 256, 34, 60]         1,180,672\n",
       "│    └─Sequential: 2-8                        [16, 512, 17, 30]         --\n",
       "│    │    └─BasicBlock: 3-14                  [16, 512, 17, 30]         3,673,088\n",
       "│    │    └─BasicBlock: 3-15                  [16, 512, 17, 30]         4,720,640\n",
       "│    │    └─BasicBlock: 3-16                  [16, 512, 17, 30]         4,720,640\n",
       "├─Sequential: 1-3                             [16, 4]                   --\n",
       "│    └─BatchNorm1d: 2-9                       [16, 512]                 1,024\n",
       "│    └─Linear: 2-10                           [16, 4]                   2,052\n",
       "├─Sequential: 1-4                             [16, 4]                   --\n",
       "│    └─BatchNorm1d: 2-11                      [16, 512]                 1,024\n",
       "│    └─Linear: 2-12                           [16, 4]                   2,052\n",
       "===============================================================================================\n",
       "Total params: 21,290,824\n",
       "Trainable params: 21,290,824\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 610.04\n",
       "===============================================================================================\n",
       "Input size (MB): 100.27\n",
       "Forward/backward pass size (MB): 9960.29\n",
       "Params size (MB): 85.16\n",
       "Estimated Total Size (MB): 10145.73\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = PyKitti_model().to(device, dtype=torch.float32)\n",
    "# model1 = PyKitti_model().to(device)\n",
    "parameters = filter(lambda p: p.requires_grad, model1.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.006)\n",
    "summary(model1, input_size=(16, 3, 544, 960))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "immediate-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#train(model1, optimizer, train_kitti_pt, val_kitti_pt, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-trade",
   "metadata": {},
   "source": [
    "## Automatic Mixed Precision Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "australian-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train, val dataset with the custom Dataset class\n",
    "train_kitti_amp = KittiDS(X_train, y_train['bboxes'], y_train['class'])\n",
    "val_kitti_amp = KittiDS(X_val, y_val['bboxes'], y_val['class'])\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Leverage torch dataloader for autobatching, parallelization\n",
    "train_kitti_amp = DataLoader(train_kitti_amp,\n",
    "        batch_size=batch_size, num_workers=12, shuffle=True, drop_last=True\n",
    "    )\n",
    "val_kitti_amp = DataLoader(val_kitti_amp, \n",
    "                           batch_size=batch_size, num_workers=12, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "banned-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model,optimizer,best,epoch,loss,val_loss,path):\n",
    "    \n",
    "    torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'val_loss_min': val_loss\n",
    "                }, path)\n",
    "        \n",
    "    if best:\n",
    "        best_fpath = 'model/best_model/'\n",
    "        if not(os.path.isdir(best_fpath)):\n",
    "            os.mkdir(best_fpath,0o666)\n",
    "        # copy checkpoint file to best model path folder\n",
    "        shutil.copyfile(path, best_fpath + os.path.basename(path))\n",
    "    \n",
    "def load_model():\n",
    "    model = model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer = optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    val_loss = checkpoint['val_loss_min']\n",
    "    return model, optimizer, epoch, loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "hindu-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic Mixed Precision\n",
    "def train_amp(model, optimizer, train_kitti_amp, val_kitti_amp, \n",
    "              val_loss_min = np.inf, start_epoch=0,epochs=10, C=1000):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "\n",
    "    # X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "    # y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, 0.0005,\n",
    "        cycle_momentum=False,\n",
    "        epochs=10,\n",
    "        steps_per_epoch=int(np.ceil(len(X) / batch_size)),\n",
    "    )\n",
    "    \n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # set the init scale of gradscaler to 2^14 instead of ^16\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        scheduler.step()\n",
    "        for i, (x, y_bbox, y_class) in enumerate(train_kitti_amp):\n",
    "            batch = y_class.shape[0]\n",
    "            x = x.float().to(device)\n",
    "            y_bbox = y_bbox.float().to(device)\n",
    "            y_class = y_class.long().to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # NEW\n",
    "            with torch.cuda.amp.autocast():\n",
    "                #y_pred = model(X_batch).squeeze()\n",
    "                out_class, out_bbox = model(x)\n",
    "                clf_loss = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "                # compute L1 loss\n",
    "                bbox_reg_loss = F.l1_loss(out_bbox, y_bbox, reduction=\"none\").sum(1)\n",
    "            bbox_reg_loss = bbox_reg_loss.sum()\n",
    "            # computing total loss\n",
    "            loss = clf_loss + bbox_reg_loss/C\n",
    "            # NEW\n",
    "            scaler.scale(loss).backward()\n",
    "            total += batch\n",
    "            lv = loss.detach().cpu().numpy()\n",
    "            sum_loss += lv.item()\n",
    "            _, pred = torch.max(out_class, 1)\n",
    "            correct += pred.eq(y_class).sum().item()\n",
    "\n",
    "            if i%100==0:\n",
    "                print(\"Epoch: %.3f, Batch: %d, Loss: %.3f\" % \n",
    "                      (epoch + (i/len(train_kitti_amp)),i,lv))\n",
    "\n",
    "            # NEW\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "        train_loss = sum_loss/total\n",
    "        train_acc = correct/total\n",
    "        val_loss, val_acc = val_metrics_amp(model, val_kitti_amp, C)\n",
    "        # save model checkpoint\n",
    "        save_checkpoint(model,optimizer,False,\n",
    "                        epoch,train_loss,val_loss,\n",
    "                        path = 'model/model_amp_test2_epoch_' + str(epoch))\n",
    "        \n",
    "        print(\"Epoch: \",epoch+1,\"/\",epochs,\"\\n----------------------------\")\n",
    "        print(\"Train_loss: %.3f, Train_acc: %.3f,\\nVal_loss: %.3f, Val_acc: %.3f\" % \n",
    "              (train_loss, train_acc,val_loss, val_acc))\n",
    "        \n",
    "        # save best model\n",
    "        if val_loss <= val_loss_min:\n",
    "            save_checkpoint(model,optimizer,True,\n",
    "                epoch,train_loss,val_loss,\n",
    "                path = 'model/model_amp_epoch_' + str(epoch))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "metallic-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_amp\n",
    "def val_metrics_amp(model, val_kitti_amp, C=1000):\n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    # pair .eval() with no_grad\n",
    "    # turn off grad computation\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (x, y_bbox, y_class) in enumerate(val_kitti_amp):\n",
    "            #x = torch.tensor(x, dtype=torch.float32)\n",
    "            #y_bbox = torch.tensor(y_bbox, dtype=torch.float32)\n",
    "            #y_class = torch.tensor(y_class, dtype=torch.long)\n",
    "            batch = y_class.shape[0]\n",
    "            x = x.float().to(device)\n",
    "            y_bbox = y_bbox.float().to(device)\n",
    "            y_class = y_class.long().to(device)\n",
    "            out_class, out_bbox = model.forward(x)\n",
    "            # NEW\n",
    "            with torch.cuda.amp.autocast():\n",
    "                #y_pred = model(X_batch).squeeze()\n",
    "                out_class, out_bbox = model(x)\n",
    "                clf_loss = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "                # compute L1 loss\n",
    "                bbox_reg_loss = F.l1_loss(out_bbox, y_bbox, reduction=\"none\").sum(1)\n",
    "            bbox_reg_loss = bbox_reg_loss.sum()\n",
    "                # computing total loss\n",
    "            loss = clf_loss + bbox_reg_loss/C\n",
    "            # NEW\n",
    "            lv = loss.detach().cpu().numpy()\n",
    "            sum_loss += lv.item()\n",
    "            _, pred = torch.max(out_class, 1)\n",
    "            correct += pred.eq(y_class).sum().item()\n",
    "            sum_loss += loss.item()\n",
    "            total += batch\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ideal-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.000, Batch: 0, Loss: 29.777\n",
      "Epoch: 0.027, Batch: 100, Loss: 35.534\n",
      "Epoch: 0.054, Batch: 200, Loss: 34.163\n",
      "Epoch: 0.082, Batch: 300, Loss: 28.495\n",
      "Epoch: 0.109, Batch: 400, Loss: 37.158\n",
      "Epoch: 0.136, Batch: 500, Loss: 25.211\n",
      "Epoch: 0.163, Batch: 600, Loss: 24.612\n",
      "Epoch: 0.191, Batch: 700, Loss: 26.004\n",
      "Epoch: 0.218, Batch: 800, Loss: 25.938\n",
      "Epoch: 0.245, Batch: 900, Loss: 24.602\n",
      "Epoch: 0.272, Batch: 1000, Loss: 24.826\n",
      "Epoch: 0.299, Batch: 1100, Loss: 29.143\n",
      "Epoch: 0.327, Batch: 1200, Loss: 30.870\n",
      "Epoch: 0.354, Batch: 1300, Loss: 31.296\n",
      "Epoch: 0.381, Batch: 1400, Loss: 19.984\n",
      "Epoch: 0.408, Batch: 1500, Loss: 19.988\n",
      "Epoch: 0.436, Batch: 1600, Loss: 28.700\n",
      "Epoch: 0.463, Batch: 1700, Loss: 22.841\n",
      "Epoch: 0.490, Batch: 1800, Loss: 15.245\n",
      "Epoch: 0.517, Batch: 1900, Loss: 30.577\n",
      "Epoch: 0.545, Batch: 2000, Loss: 22.152\n",
      "Epoch: 0.572, Batch: 2100, Loss: 19.359\n",
      "Epoch: 0.599, Batch: 2200, Loss: 20.681\n",
      "Epoch: 0.626, Batch: 2300, Loss: 27.132\n",
      "Epoch: 0.653, Batch: 2400, Loss: 22.988\n",
      "Epoch: 0.681, Batch: 2500, Loss: 26.103\n",
      "Epoch: 0.708, Batch: 2600, Loss: 25.342\n",
      "Epoch: 0.735, Batch: 2700, Loss: 26.479\n",
      "Epoch: 0.762, Batch: 2800, Loss: 22.416\n",
      "Epoch: 0.790, Batch: 2900, Loss: 20.567\n",
      "Epoch: 0.817, Batch: 3000, Loss: 22.793\n",
      "Epoch: 0.844, Batch: 3100, Loss: 20.547\n",
      "Epoch: 0.871, Batch: 3200, Loss: 19.212\n",
      "Epoch: 0.898, Batch: 3300, Loss: 19.107\n",
      "Epoch: 0.926, Batch: 3400, Loss: 17.121\n",
      "Epoch: 0.953, Batch: 3500, Loss: 20.051\n",
      "Epoch: 0.980, Batch: 3600, Loss: 23.710\n",
      "Epoch:  1 / 5 \n",
      "----------------------------\n",
      "Train_loss: 1.515, Train_acc: 0.702,\n",
      "Val_loss: 2.755, Val_acc: 0.706\n",
      "Epoch: 1.000, Batch: 0, Loss: 21.442\n",
      "Epoch: 1.027, Batch: 100, Loss: 30.572\n",
      "Epoch: 1.054, Batch: 200, Loss: 25.939\n",
      "Epoch: 1.082, Batch: 300, Loss: 20.940\n",
      "Epoch: 1.109, Batch: 400, Loss: 20.291\n",
      "Epoch: 1.136, Batch: 500, Loss: 26.905\n",
      "Epoch: 1.163, Batch: 600, Loss: 26.383\n",
      "Epoch: 1.191, Batch: 700, Loss: 22.546\n",
      "Epoch: 1.218, Batch: 800, Loss: 28.365\n",
      "Epoch: 1.245, Batch: 900, Loss: 29.977\n",
      "Epoch: 1.272, Batch: 1000, Loss: 21.614\n",
      "Epoch: 1.299, Batch: 1100, Loss: 26.021\n",
      "Epoch: 1.327, Batch: 1200, Loss: 24.629\n",
      "Epoch: 1.354, Batch: 1300, Loss: 24.772\n",
      "Epoch: 1.381, Batch: 1400, Loss: 25.296\n",
      "Epoch: 1.408, Batch: 1500, Loss: 18.900\n",
      "Epoch: 1.436, Batch: 1600, Loss: 28.297\n",
      "Epoch: 1.463, Batch: 1700, Loss: 27.541\n",
      "Epoch: 1.490, Batch: 1800, Loss: 28.485\n",
      "Epoch: 1.517, Batch: 1900, Loss: 18.774\n",
      "Epoch: 1.545, Batch: 2000, Loss: 25.925\n",
      "Epoch: 1.572, Batch: 2100, Loss: 26.030\n",
      "Epoch: 1.599, Batch: 2200, Loss: 32.088\n",
      "Epoch: 1.626, Batch: 2300, Loss: 26.731\n",
      "Epoch: 1.653, Batch: 2400, Loss: 26.713\n",
      "Epoch: 1.681, Batch: 2500, Loss: 25.143\n",
      "Epoch: 1.708, Batch: 2600, Loss: 27.878\n",
      "Epoch: 1.735, Batch: 2700, Loss: 21.334\n",
      "Epoch: 1.762, Batch: 2800, Loss: 21.186\n",
      "Epoch: 1.790, Batch: 2900, Loss: 19.128\n",
      "Epoch: 1.817, Batch: 3000, Loss: 27.999\n",
      "Epoch: 1.844, Batch: 3100, Loss: 24.211\n",
      "Epoch: 1.871, Batch: 3200, Loss: 17.319\n",
      "Epoch: 1.898, Batch: 3300, Loss: 21.240\n",
      "Epoch: 1.926, Batch: 3400, Loss: 20.046\n",
      "Epoch: 1.953, Batch: 3500, Loss: 22.971\n",
      "Epoch: 1.980, Batch: 3600, Loss: 24.680\n",
      "Epoch:  2 / 5 \n",
      "----------------------------\n",
      "Train_loss: 1.578, Train_acc: 0.674,\n",
      "Val_loss: 3.015, Val_acc: 0.688\n",
      "Epoch: 2.000, Batch: 0, Loss: 25.893\n",
      "Epoch: 2.027, Batch: 100, Loss: 25.008\n",
      "Epoch: 2.054, Batch: 200, Loss: 23.092\n",
      "Epoch: 2.082, Batch: 300, Loss: 19.064\n",
      "Epoch: 2.109, Batch: 400, Loss: 23.440\n",
      "Epoch: 2.136, Batch: 500, Loss: 23.313\n",
      "Epoch: 2.163, Batch: 600, Loss: 22.794\n",
      "Epoch: 2.191, Batch: 700, Loss: 25.247\n",
      "Epoch: 2.218, Batch: 800, Loss: 26.507\n",
      "Epoch: 2.245, Batch: 900, Loss: 25.170\n",
      "Epoch: 2.272, Batch: 1000, Loss: 21.564\n",
      "Epoch: 2.299, Batch: 1100, Loss: 32.877\n",
      "Epoch: 2.327, Batch: 1200, Loss: 20.609\n",
      "Epoch: 2.354, Batch: 1300, Loss: 19.614\n",
      "Epoch: 2.381, Batch: 1400, Loss: 20.962\n",
      "Epoch: 2.408, Batch: 1500, Loss: 22.852\n",
      "Epoch: 2.436, Batch: 1600, Loss: 25.781\n",
      "Epoch: 2.463, Batch: 1700, Loss: 29.566\n",
      "Epoch: 2.490, Batch: 1800, Loss: 25.994\n",
      "Epoch: 2.517, Batch: 1900, Loss: 27.007\n",
      "Epoch: 2.545, Batch: 2000, Loss: 25.934\n",
      "Epoch: 2.572, Batch: 2100, Loss: 22.544\n",
      "Epoch: 2.599, Batch: 2200, Loss: 27.214\n",
      "Epoch: 2.626, Batch: 2300, Loss: 19.161\n",
      "Epoch: 2.653, Batch: 2400, Loss: 20.503\n",
      "Epoch: 2.681, Batch: 2500, Loss: 17.021\n",
      "Epoch: 2.708, Batch: 2600, Loss: 28.035\n",
      "Epoch: 2.735, Batch: 2700, Loss: 24.178\n",
      "Epoch: 2.762, Batch: 2800, Loss: 21.419\n",
      "Epoch: 2.790, Batch: 2900, Loss: 23.510\n",
      "Epoch: 2.817, Batch: 3000, Loss: 23.338\n",
      "Epoch: 2.844, Batch: 3100, Loss: 23.541\n",
      "Epoch: 2.871, Batch: 3200, Loss: 27.241\n",
      "Epoch: 2.898, Batch: 3300, Loss: 24.876\n",
      "Epoch: 2.926, Batch: 3400, Loss: 22.735\n",
      "Epoch: 2.953, Batch: 3500, Loss: 28.093\n",
      "Epoch: 2.980, Batch: 3600, Loss: 20.490\n",
      "Epoch:  3 / 5 \n",
      "----------------------------\n",
      "Train_loss: 1.539, Train_acc: 0.680,\n",
      "Val_loss: 2.873, Val_acc: 0.699\n",
      "Epoch: 3.000, Batch: 0, Loss: 28.575\n",
      "Epoch: 3.027, Batch: 100, Loss: 25.492\n",
      "Epoch: 3.054, Batch: 200, Loss: 29.438\n",
      "Epoch: 3.082, Batch: 300, Loss: 21.813\n",
      "Epoch: 3.109, Batch: 400, Loss: 24.824\n",
      "Epoch: 3.136, Batch: 500, Loss: 24.653\n",
      "Epoch: 3.163, Batch: 600, Loss: 25.335\n",
      "Epoch: 3.191, Batch: 700, Loss: 17.685\n",
      "Epoch: 3.218, Batch: 800, Loss: 21.568\n",
      "Epoch: 3.245, Batch: 900, Loss: 27.922\n",
      "Epoch: 3.272, Batch: 1000, Loss: 16.980\n",
      "Epoch: 3.299, Batch: 1100, Loss: 19.851\n",
      "Epoch: 3.327, Batch: 1200, Loss: 25.322\n",
      "Epoch: 3.354, Batch: 1300, Loss: 19.256\n",
      "Epoch: 3.381, Batch: 1400, Loss: 24.922\n",
      "Epoch: 3.408, Batch: 1500, Loss: 17.580\n",
      "Epoch: 3.436, Batch: 1600, Loss: 21.802\n",
      "Epoch: 3.463, Batch: 1700, Loss: 18.707\n",
      "Epoch: 3.490, Batch: 1800, Loss: 29.322\n",
      "Epoch: 3.517, Batch: 1900, Loss: 27.073\n",
      "Epoch: 3.545, Batch: 2000, Loss: 17.905\n",
      "Epoch: 3.572, Batch: 2100, Loss: 18.418\n",
      "Epoch: 3.599, Batch: 2200, Loss: 28.578\n",
      "Epoch: 3.626, Batch: 2300, Loss: 21.652\n",
      "Epoch: 3.653, Batch: 2400, Loss: 16.117\n",
      "Epoch: 3.681, Batch: 2500, Loss: 20.155\n",
      "Epoch: 3.708, Batch: 2600, Loss: 24.161\n",
      "Epoch: 3.735, Batch: 2700, Loss: 21.511\n",
      "Epoch: 3.762, Batch: 2800, Loss: 17.308\n",
      "Epoch: 3.790, Batch: 2900, Loss: 21.451\n",
      "Epoch: 3.817, Batch: 3000, Loss: 24.802\n",
      "Epoch: 3.844, Batch: 3100, Loss: 24.733\n",
      "Epoch: 3.871, Batch: 3200, Loss: 24.484\n",
      "Epoch: 3.898, Batch: 3300, Loss: 22.599\n",
      "Epoch: 3.926, Batch: 3400, Loss: 17.014\n",
      "Epoch: 3.953, Batch: 3500, Loss: 33.632\n",
      "Epoch: 3.980, Batch: 3600, Loss: 28.096\n",
      "Epoch:  4 / 5 \n",
      "----------------------------\n",
      "Train_loss: 1.504, Train_acc: 0.685,\n",
      "Val_loss: 2.830, Val_acc: 0.702\n",
      "Epoch: 4.000, Batch: 0, Loss: 25.047\n",
      "Epoch: 4.027, Batch: 100, Loss: 27.943\n",
      "Epoch: 4.054, Batch: 200, Loss: 23.171\n",
      "Epoch: 4.082, Batch: 300, Loss: 30.334\n",
      "Epoch: 4.109, Batch: 400, Loss: 20.448\n",
      "Epoch: 4.136, Batch: 500, Loss: 23.372\n",
      "Epoch: 4.163, Batch: 600, Loss: 22.817\n",
      "Epoch: 4.191, Batch: 700, Loss: 20.237\n",
      "Epoch: 4.218, Batch: 800, Loss: 22.833\n",
      "Epoch: 4.245, Batch: 900, Loss: 19.698\n",
      "Epoch: 4.272, Batch: 1000, Loss: 21.571\n",
      "Epoch: 4.299, Batch: 1100, Loss: 21.764\n",
      "Epoch: 4.327, Batch: 1200, Loss: 23.672\n",
      "Epoch: 4.354, Batch: 1300, Loss: 17.301\n",
      "Epoch: 4.381, Batch: 1400, Loss: 21.343\n",
      "Epoch: 4.408, Batch: 1500, Loss: 18.251\n",
      "Epoch: 4.436, Batch: 1600, Loss: 21.906\n",
      "Epoch: 4.463, Batch: 1700, Loss: 32.777\n",
      "Epoch: 4.490, Batch: 1800, Loss: 17.421\n",
      "Epoch: 4.517, Batch: 1900, Loss: 23.981\n",
      "Epoch: 4.545, Batch: 2000, Loss: 26.357\n",
      "Epoch: 4.572, Batch: 2100, Loss: 21.309\n",
      "Epoch: 4.599, Batch: 2200, Loss: 20.689\n",
      "Epoch: 4.626, Batch: 2300, Loss: 23.344\n",
      "Epoch: 4.653, Batch: 2400, Loss: 19.472\n",
      "Epoch: 4.681, Batch: 2500, Loss: 32.371\n",
      "Epoch: 4.708, Batch: 2600, Loss: 18.104\n",
      "Epoch: 4.735, Batch: 2700, Loss: 21.630\n",
      "Epoch: 4.762, Batch: 2800, Loss: 16.155\n",
      "Epoch: 4.790, Batch: 2900, Loss: 20.170\n",
      "Epoch: 4.817, Batch: 3000, Loss: 18.946\n",
      "Epoch: 4.844, Batch: 3100, Loss: 24.720\n",
      "Epoch: 4.871, Batch: 3200, Loss: 22.639\n",
      "Epoch: 4.898, Batch: 3300, Loss: 22.006\n",
      "Epoch: 4.926, Batch: 3400, Loss: 23.574\n",
      "Epoch: 4.953, Batch: 3500, Loss: 20.553\n",
      "Epoch: 4.980, Batch: 3600, Loss: 21.401\n",
      "Epoch:  5 / 5 \n",
      "----------------------------\n",
      "Train_loss: 1.472, Train_acc: 0.690,\n",
      "Val_loss: 2.680, Val_acc: 0.705\n",
      "CPU times: user 3h 35min 25s, sys: 1h 11min 32s, total: 4h 46min 58s\n",
      "Wall time: 3h 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_amp(model1, optimizer, train_kitti_amp, val_kitti_amp, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "innovative-rwanda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 15 13:58:13 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 3080    Off  | 00000000:09:00.0  On |                  N/A |\r\n",
      "|  0%   49C    P8    30W / 320W |   2858MiB / 10014MiB |      4%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "durable-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifications for Model-2\n",
    "class PyKitti_model_test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PyKitti_model_test, self).__init__()\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "        # children returns immediate child modules\n",
    "        layers = list(resnet.children())[:6]\n",
    "        self.features1 = nn.Sequential(*layers[:4])\n",
    "        self.features2 = nn.Sequential(*layers[4:])\n",
    "        # classification network\n",
    "        self.classifier = nn.Sequential(nn.BatchNorm1d(128), nn.Linear(128, 4))\n",
    "        # bbox regressor network\n",
    "        self.bbox = nn.Sequential(nn.BatchNorm1d(128), nn.Linear(128, 4))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features1(x)\n",
    "        # print(\"x shape after extracting features1: \", x.shape)\n",
    "        x = self.features2(x)\n",
    "        # print(\"x shape after extracting features2: \", x.shape)\n",
    "        x = F.relu(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
    "        # print(\"x shape before reshape: \", x.shape)\n",
    "        # reshape tensor\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        return self.classifier(x), self.bbox(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "welsh-colon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "PyKitti_model_test                            --                        --\n",
       "├─Sequential: 1-1                             [16, 64, 136, 240]        --\n",
       "│    └─Conv2d: 2-1                            [16, 64, 272, 480]        9,408\n",
       "│    └─BatchNorm2d: 2-2                       [16, 64, 272, 480]        128\n",
       "│    └─ReLU: 2-3                              [16, 64, 272, 480]        --\n",
       "│    └─MaxPool2d: 2-4                         [16, 64, 136, 240]        --\n",
       "├─Sequential: 1-2                             [16, 128, 68, 120]        --\n",
       "│    └─Sequential: 2-5                        [16, 64, 136, 240]        --\n",
       "│    │    └─BasicBlock: 3-1                   [16, 64, 136, 240]        73,984\n",
       "│    │    └─BasicBlock: 3-2                   [16, 64, 136, 240]        73,984\n",
       "│    │    └─BasicBlock: 3-3                   [16, 64, 136, 240]        73,984\n",
       "│    └─Sequential: 2-6                        [16, 128, 68, 120]        --\n",
       "│    │    └─BasicBlock: 3-4                   [16, 128, 68, 120]        230,144\n",
       "│    │    └─BasicBlock: 3-5                   [16, 128, 68, 120]        295,424\n",
       "│    │    └─BasicBlock: 3-6                   [16, 128, 68, 120]        295,424\n",
       "│    │    └─BasicBlock: 3-7                   [16, 128, 68, 120]        295,424\n",
       "├─Sequential: 1-3                             [16, 4]                   --\n",
       "│    └─BatchNorm1d: 2-7                       [16, 128]                 256\n",
       "│    └─Linear: 2-8                            [16, 4]                   516\n",
       "├─Sequential: 1-4                             [16, 4]                   --\n",
       "│    └─BatchNorm1d: 2-9                       [16, 128]                 256\n",
       "│    └─Linear: 2-10                           [16, 4]                   516\n",
       "===============================================================================================\n",
       "Total params: 1,349,448\n",
       "Trainable params: 1,349,448\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 280.62\n",
       "===============================================================================================\n",
       "Input size (MB): 100.27\n",
       "Forward/backward pass size (MB): 7754.25\n",
       "Params size (MB): 5.40\n",
       "Estimated Total Size (MB): 7859.92\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = PyKitti_model_test().to(device, dtype=torch.float32)\n",
    "# model1 = PyKitti_model().to(device)\n",
    "parameters = filter(lambda p: p.requires_grad, model2.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.0005)\n",
    "summary(model2, input_size=(16, 3, 544, 960))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "elegant-concert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.000, Batch: 0, Loss: 42.588\n",
      "Epoch: 0.027, Batch: 100, Loss: 41.866\n",
      "Epoch: 0.054, Batch: 200, Loss: 43.622\n",
      "Epoch: 0.082, Batch: 300, Loss: 41.993\n",
      "Epoch: 0.109, Batch: 400, Loss: 45.641\n",
      "Epoch: 0.136, Batch: 500, Loss: 42.956\n",
      "Epoch: 0.163, Batch: 600, Loss: 42.640\n",
      "Epoch: 0.191, Batch: 700, Loss: 43.444\n",
      "Epoch: 0.218, Batch: 800, Loss: 42.373\n",
      "Epoch: 0.245, Batch: 900, Loss: 42.303\n",
      "Epoch: 0.272, Batch: 1000, Loss: 42.459\n",
      "Epoch: 0.299, Batch: 1100, Loss: 39.261\n",
      "Epoch: 0.327, Batch: 1200, Loss: 34.727\n",
      "Epoch: 0.354, Batch: 1300, Loss: 43.471\n",
      "Epoch: 0.381, Batch: 1400, Loss: 46.605\n",
      "Epoch: 0.408, Batch: 1500, Loss: 44.151\n",
      "Epoch: 0.436, Batch: 1600, Loss: 31.112\n",
      "Epoch: 0.463, Batch: 1700, Loss: 46.553\n",
      "Epoch: 0.490, Batch: 1800, Loss: 46.151\n",
      "Epoch: 0.517, Batch: 1900, Loss: 44.388\n",
      "Epoch: 0.545, Batch: 2000, Loss: 43.423\n",
      "Epoch: 0.572, Batch: 2100, Loss: 41.446\n",
      "Epoch: 0.599, Batch: 2200, Loss: 47.964\n",
      "Epoch: 0.626, Batch: 2300, Loss: 41.638\n",
      "Epoch: 0.653, Batch: 2400, Loss: 43.767\n",
      "Epoch: 0.681, Batch: 2500, Loss: 37.627\n",
      "Epoch: 0.708, Batch: 2600, Loss: 47.540\n",
      "Epoch: 0.735, Batch: 2700, Loss: 38.585\n",
      "Epoch: 0.762, Batch: 2800, Loss: 38.994\n",
      "Epoch: 0.790, Batch: 2900, Loss: 42.975\n",
      "Epoch: 0.817, Batch: 3000, Loss: 42.006\n",
      "Epoch: 0.844, Batch: 3100, Loss: 42.409\n",
      "Epoch: 0.871, Batch: 3200, Loss: 33.847\n",
      "Epoch: 0.898, Batch: 3300, Loss: 38.295\n",
      "Epoch: 0.926, Batch: 3400, Loss: 38.353\n",
      "Epoch: 0.953, Batch: 3500, Loss: 40.090\n",
      "Epoch: 0.980, Batch: 3600, Loss: 42.324\n",
      "Epoch:  1 / 5 \n",
      "----------------------------\n",
      "Train_loss: 2.655, Train_acc: 0.709,\n",
      "Val_loss: 5.229, Val_acc: 0.709\n",
      "Epoch: 1.000, Batch: 0, Loss: 37.168\n",
      "Epoch: 1.027, Batch: 100, Loss: 38.677\n",
      "Epoch: 1.054, Batch: 200, Loss: 26.599\n",
      "Epoch: 1.082, Batch: 300, Loss: 24.420\n",
      "Epoch: 1.109, Batch: 400, Loss: 28.680\n",
      "Epoch: 1.136, Batch: 500, Loss: 24.707\n",
      "Epoch: 1.163, Batch: 600, Loss: 18.092\n",
      "Epoch: 1.191, Batch: 700, Loss: 28.085\n",
      "Epoch: 1.218, Batch: 800, Loss: 26.201\n",
      "Epoch: 1.245, Batch: 900, Loss: 24.054\n",
      "Epoch: 1.272, Batch: 1000, Loss: 31.951\n",
      "Epoch: 1.299, Batch: 1100, Loss: 24.014\n",
      "Epoch: 1.327, Batch: 1200, Loss: 24.109\n",
      "Epoch: 1.354, Batch: 1300, Loss: 22.715\n",
      "Epoch: 1.381, Batch: 1400, Loss: 21.260\n",
      "Epoch: 1.408, Batch: 1500, Loss: 24.617\n",
      "Epoch: 1.436, Batch: 1600, Loss: 21.348\n",
      "Epoch: 1.463, Batch: 1700, Loss: 22.925\n",
      "Epoch: 1.490, Batch: 1800, Loss: 19.848\n",
      "Epoch: 1.517, Batch: 1900, Loss: 21.526\n",
      "Epoch: 1.545, Batch: 2000, Loss: 22.384\n",
      "Epoch: 1.572, Batch: 2100, Loss: 26.830\n",
      "Epoch: 1.599, Batch: 2200, Loss: 26.771\n",
      "Epoch: 1.626, Batch: 2300, Loss: 22.431\n",
      "Epoch: 1.653, Batch: 2400, Loss: 25.234\n",
      "Epoch: 1.681, Batch: 2500, Loss: 23.644\n",
      "Epoch: 1.708, Batch: 2600, Loss: 21.069\n",
      "Epoch: 1.735, Batch: 2700, Loss: 18.093\n",
      "Epoch: 1.762, Batch: 2800, Loss: 18.248\n",
      "Epoch: 1.790, Batch: 2900, Loss: 21.255\n",
      "Epoch: 1.817, Batch: 3000, Loss: 22.169\n",
      "Epoch: 1.844, Batch: 3100, Loss: 25.846\n",
      "Epoch: 1.871, Batch: 3200, Loss: 24.414\n",
      "Epoch: 1.898, Batch: 3300, Loss: 27.972\n",
      "Epoch: 1.926, Batch: 3400, Loss: 28.497\n",
      "Epoch: 1.953, Batch: 3500, Loss: 32.032\n",
      "Epoch: 1.980, Batch: 3600, Loss: 21.856\n",
      "Epoch:  2 / 5 \n",
      "----------------------------\n",
      "Train_loss: 2.098, Train_acc: 0.697,\n",
      "Val_loss: 3.009, Val_acc: 0.641\n",
      "Epoch: 2.000, Batch: 0, Loss: 20.067\n",
      "Epoch: 2.027, Batch: 100, Loss: 23.587\n",
      "Epoch: 2.054, Batch: 200, Loss: 19.169\n",
      "Epoch: 2.082, Batch: 300, Loss: 25.801\n",
      "Epoch: 2.109, Batch: 400, Loss: 16.310\n",
      "Epoch: 2.136, Batch: 500, Loss: 23.026\n",
      "Epoch: 2.163, Batch: 600, Loss: 18.141\n",
      "Epoch: 2.191, Batch: 700, Loss: 20.881\n",
      "Epoch: 2.218, Batch: 800, Loss: 22.538\n",
      "Epoch: 2.245, Batch: 900, Loss: 32.062\n",
      "Epoch: 2.272, Batch: 1000, Loss: 23.322\n",
      "Epoch: 2.299, Batch: 1100, Loss: 16.849\n",
      "Epoch: 2.327, Batch: 1200, Loss: 25.679\n",
      "Epoch: 2.354, Batch: 1300, Loss: 22.051\n",
      "Epoch: 2.381, Batch: 1400, Loss: 15.882\n",
      "Epoch: 2.408, Batch: 1500, Loss: 19.690\n",
      "Epoch: 2.436, Batch: 1600, Loss: 19.171\n",
      "Epoch: 2.463, Batch: 1700, Loss: 18.760\n",
      "Epoch: 2.490, Batch: 1800, Loss: 17.489\n",
      "Epoch: 2.517, Batch: 1900, Loss: 19.895\n",
      "Epoch: 2.545, Batch: 2000, Loss: 21.388\n",
      "Epoch: 2.572, Batch: 2100, Loss: 24.842\n",
      "Epoch: 2.599, Batch: 2200, Loss: 20.488\n",
      "Epoch: 2.626, Batch: 2300, Loss: 23.348\n",
      "Epoch: 2.653, Batch: 2400, Loss: 20.159\n",
      "Epoch: 2.681, Batch: 2500, Loss: 26.252\n",
      "Epoch: 2.708, Batch: 2600, Loss: 27.654\n",
      "Epoch: 2.735, Batch: 2700, Loss: 23.205\n",
      "Epoch: 2.762, Batch: 2800, Loss: 17.992\n",
      "Epoch: 2.790, Batch: 2900, Loss: 20.701\n",
      "Epoch: 2.817, Batch: 3000, Loss: 18.900\n",
      "Epoch: 2.844, Batch: 3100, Loss: 20.157\n",
      "Epoch: 2.871, Batch: 3200, Loss: 34.250\n",
      "Epoch: 2.898, Batch: 3300, Loss: 23.432\n",
      "Epoch: 2.926, Batch: 3400, Loss: 15.961\n",
      "Epoch: 2.953, Batch: 3500, Loss: 16.794\n",
      "Epoch: 2.980, Batch: 3600, Loss: 22.435\n",
      "Epoch:  3 / 5 \n",
      "----------------------------\n",
      "Train_loss: 1.882, Train_acc: 0.697,\n",
      "Val_loss: 2.968, Val_acc: 0.680\n",
      "Epoch: 3.000, Batch: 0, Loss: 20.090\n",
      "Epoch: 3.027, Batch: 100, Loss: 19.361\n",
      "Epoch: 3.054, Batch: 200, Loss: 36.386\n",
      "Epoch: 3.082, Batch: 300, Loss: 22.158\n",
      "Epoch: 3.109, Batch: 400, Loss: 20.956\n",
      "Epoch: 3.136, Batch: 500, Loss: 24.415\n",
      "Epoch: 3.163, Batch: 600, Loss: 22.723\n",
      "Epoch: 3.191, Batch: 700, Loss: 16.858\n",
      "Epoch: 3.218, Batch: 800, Loss: 19.682\n",
      "Epoch: 3.245, Batch: 900, Loss: 26.708\n",
      "Epoch: 3.272, Batch: 1000, Loss: 20.954\n",
      "Epoch: 3.299, Batch: 1100, Loss: 20.709\n",
      "Epoch: 3.327, Batch: 1200, Loss: 17.329\n",
      "Epoch: 3.354, Batch: 1300, Loss: 21.788\n",
      "Epoch: 3.381, Batch: 1400, Loss: 18.569\n",
      "Epoch: 3.408, Batch: 1500, Loss: 22.725\n",
      "Epoch: 3.436, Batch: 1600, Loss: 21.632\n",
      "Epoch: 3.463, Batch: 1700, Loss: 19.748\n",
      "Epoch: 3.490, Batch: 1800, Loss: 20.650\n",
      "Epoch: 3.517, Batch: 1900, Loss: 19.934\n",
      "Epoch: 3.545, Batch: 2000, Loss: 18.544\n",
      "Epoch: 3.572, Batch: 2100, Loss: 17.642\n",
      "Epoch: 3.599, Batch: 2200, Loss: 16.269\n",
      "Epoch: 3.626, Batch: 2300, Loss: 23.840\n",
      "Epoch: 3.653, Batch: 2400, Loss: 18.327\n",
      "Epoch: 3.681, Batch: 2500, Loss: 26.494\n",
      "Epoch: 3.708, Batch: 2600, Loss: 28.350\n",
      "Epoch: 3.735, Batch: 2700, Loss: 34.523\n",
      "Epoch: 3.762, Batch: 2800, Loss: 23.568\n",
      "Epoch: 3.790, Batch: 2900, Loss: 20.806\n",
      "Epoch: 3.817, Batch: 3000, Loss: 27.577\n",
      "Epoch: 3.844, Batch: 3100, Loss: 24.057\n",
      "Epoch: 3.871, Batch: 3200, Loss: 23.410\n",
      "Epoch: 3.898, Batch: 3300, Loss: 18.914\n",
      "Epoch: 3.926, Batch: 3400, Loss: 22.277\n",
      "Epoch: 3.953, Batch: 3500, Loss: 27.789\n",
      "Epoch: 3.980, Batch: 3600, Loss: 26.159\n",
      "Epoch:  4 / 5 \n",
      "----------------------------\n",
      "Train_loss: 1.769, Train_acc: 0.698,\n",
      "Val_loss: 2.934, Val_acc: 0.693\n",
      "Epoch: 4.000, Batch: 0, Loss: 21.910\n",
      "Epoch: 4.027, Batch: 100, Loss: 19.910\n",
      "Epoch: 4.054, Batch: 200, Loss: 24.390\n",
      "Epoch: 4.082, Batch: 300, Loss: 24.550\n",
      "Epoch: 4.109, Batch: 400, Loss: 22.453\n",
      "Epoch: 4.136, Batch: 500, Loss: 19.970\n",
      "Epoch: 4.163, Batch: 600, Loss: 24.328\n",
      "Epoch: 4.191, Batch: 700, Loss: 20.650\n",
      "Epoch: 4.218, Batch: 800, Loss: 18.088\n",
      "Epoch: 4.245, Batch: 900, Loss: 25.294\n",
      "Epoch: 4.272, Batch: 1000, Loss: 20.602\n",
      "Epoch: 4.299, Batch: 1100, Loss: 23.320\n",
      "Epoch: 4.327, Batch: 1200, Loss: 20.850\n",
      "Epoch: 4.354, Batch: 1300, Loss: 16.654\n",
      "Epoch: 4.381, Batch: 1400, Loss: 22.115\n",
      "Epoch: 4.408, Batch: 1500, Loss: 22.389\n",
      "Epoch: 4.436, Batch: 1600, Loss: 20.590\n",
      "Epoch: 4.463, Batch: 1700, Loss: 29.061\n",
      "Epoch: 4.490, Batch: 1800, Loss: 19.158\n",
      "Epoch: 4.517, Batch: 1900, Loss: 23.264\n",
      "Epoch: 4.545, Batch: 2000, Loss: 33.958\n",
      "Epoch: 4.572, Batch: 2100, Loss: 16.241\n",
      "Epoch: 4.599, Batch: 2200, Loss: 28.777\n",
      "Epoch: 4.626, Batch: 2300, Loss: 20.824\n",
      "Epoch: 4.653, Batch: 2400, Loss: 21.758\n",
      "Epoch: 4.681, Batch: 2500, Loss: 30.657\n",
      "Epoch: 4.708, Batch: 2600, Loss: 32.057\n",
      "Epoch: 4.735, Batch: 2700, Loss: 26.582\n",
      "Epoch: 4.762, Batch: 2800, Loss: 23.310\n",
      "Epoch: 4.790, Batch: 2900, Loss: 21.861\n",
      "Epoch: 4.817, Batch: 3000, Loss: 25.266\n",
      "Epoch: 4.844, Batch: 3100, Loss: 21.125\n",
      "Epoch: 4.871, Batch: 3200, Loss: 21.450\n",
      "Epoch: 4.898, Batch: 3300, Loss: 22.673\n",
      "Epoch: 4.926, Batch: 3400, Loss: 22.286\n",
      "Epoch: 4.953, Batch: 3500, Loss: 21.291\n",
      "Epoch: 4.980, Batch: 3600, Loss: 22.038\n",
      "Epoch:  5 / 5 \n",
      "----------------------------\n",
      "Train_loss: 1.699, Train_acc: 0.699,\n",
      "Val_loss: 2.949, Val_acc: 0.685\n",
      "CPU times: user 45min 28s, sys: 25min 57s, total: 1h 11min 25s\n",
      "Wall time: 1h 12min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_amp(model2, optimizer, train_kitti_amp, val_kitti_amp, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-basics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
