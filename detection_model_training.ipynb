{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "architectural-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from utils import helper\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "supported-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "# Columns: image_path, label_path, bboxes, classes\n",
    "impath = 'data/kitti/augmented_test/images/'\n",
    "labels_path = 'data/kitti/augmented_test/labels/'\n",
    "imlabel_list = helper.imlabel(impath, labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alert-kidney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/kitti/augmented_test/images/2-wheeler-10_resized_brightness.jpg'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imlabel_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "laden-ancient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_path</th>\n",
       "      <th>class</th>\n",
       "      <th>bboxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/kitti/augmented_test/images/2-wheeler-10_...</td>\n",
       "      <td>data/kitti/augmented_test/labels/2-wheeler-10_...</td>\n",
       "      <td>pedestrian</td>\n",
       "      <td>[862.2254025044723, 150.72, 926.4543828264759,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/kitti/augmented_test/images/2-wheeler-10_...</td>\n",
       "      <td>data/kitti/augmented_test/labels/2-wheeler-10_...</td>\n",
       "      <td>pedestrian</td>\n",
       "      <td>[871.9570661896244, 111.36, 917.6958855098391,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/kitti/augmented_test/images/2-wheeler-10_...</td>\n",
       "      <td>data/kitti/augmented_test/labels/2-wheeler-10_...</td>\n",
       "      <td>2-wheeler</td>\n",
       "      <td>[83.6923076923077, 131.51999999999998, 282.218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/kitti/augmented_test/images/2-wheeler-10_...</td>\n",
       "      <td>data/kitti/augmented_test/labels/2-wheeler-10_...</td>\n",
       "      <td>2-wheeler</td>\n",
       "      <td>[295.84257602862255, 120.96, 476.8515205724508...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/kitti/augmented_test/images/2-wheeler-10_...</td>\n",
       "      <td>data/kitti/augmented_test/labels/2-wheeler-10_...</td>\n",
       "      <td>2-wheeler</td>\n",
       "      <td>[484.63685152057246, 121.92, 615.0411449016101...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  \\\n",
       "0  data/kitti/augmented_test/images/2-wheeler-10_...   \n",
       "1  data/kitti/augmented_test/images/2-wheeler-10_...   \n",
       "2  data/kitti/augmented_test/images/2-wheeler-10_...   \n",
       "3  data/kitti/augmented_test/images/2-wheeler-10_...   \n",
       "4  data/kitti/augmented_test/images/2-wheeler-10_...   \n",
       "\n",
       "                                          label_path       class  \\\n",
       "0  data/kitti/augmented_test/labels/2-wheeler-10_...  pedestrian   \n",
       "1  data/kitti/augmented_test/labels/2-wheeler-10_...  pedestrian   \n",
       "2  data/kitti/augmented_test/labels/2-wheeler-10_...   2-wheeler   \n",
       "3  data/kitti/augmented_test/labels/2-wheeler-10_...   2-wheeler   \n",
       "4  data/kitti/augmented_test/labels/2-wheeler-10_...   2-wheeler   \n",
       "\n",
       "                                              bboxes  \n",
       "0  [862.2254025044723, 150.72, 926.4543828264759,...  \n",
       "1  [871.9570661896244, 111.36, 917.6958855098391,...  \n",
       "2  [83.6923076923077, 131.51999999999998, 282.218...  \n",
       "3  [295.84257602862255, 120.96, 476.8515205724508...  \n",
       "4  [484.63685152057246, 121.92, 615.0411449016101...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['image_path','label_path','class','bboxes'])\n",
    "# df = pd.DataFrame()\n",
    "# df['image_path'] = imlabel_list[:][0]\n",
    "# df['label_path'] = imlabel_list[:][1]\n",
    "# df.head()\n",
    "\n",
    "for item in imlabel_list:\n",
    "    #bboxes = helper.fetch_bboxes(item[1]).tolist()\n",
    "    bboxes = helper.fetch_bboxes(item[1])\n",
    "    classes = helper.fetch_classes(item[1])\n",
    "    for i,cls_bbox in enumerate(zip(classes,bboxes)):\n",
    "        # print(cls_bbox)\n",
    "        #df.loc[i,'image_path'] = item[0]\n",
    "        #df.loc[i,'label_path'] = item[1]\n",
    "        #df.loc[i,'class'] = cls_bbox[0]\n",
    "        \n",
    "        #df.loc[i,'bboxes'] = cls_bbox[1]\n",
    "        # df = df.append([item[0],item[1],cls_bbox[0],cls_bbox[1]])\n",
    "        df = df.append({'image_path':item[0], 'label_path': item[1],\n",
    "                        'class': cls_bbox[0], 'bboxes': cls_bbox[1][:4]}, ignore_index=True)\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bright-racing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pedestrian' '2-wheeler' 'car' 'dontcare']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_path</th>\n",
       "      <th>class</th>\n",
       "      <th>bboxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/kitti/augmented_test/images/2-wheeler-10_...</td>\n",
       "      <td>data/kitti/augmented_test/labels/2-wheeler-10_...</td>\n",
       "      <td>1</td>\n",
       "      <td>[862.2254025044723, 150.72, 926.4543828264759,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/kitti/augmented_test/images/2-wheeler-10_...</td>\n",
       "      <td>data/kitti/augmented_test/labels/2-wheeler-10_...</td>\n",
       "      <td>1</td>\n",
       "      <td>[871.9570661896244, 111.36, 917.6958855098391,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/kitti/augmented_test/images/2-wheeler-10_...</td>\n",
       "      <td>data/kitti/augmented_test/labels/2-wheeler-10_...</td>\n",
       "      <td>0</td>\n",
       "      <td>[83.6923076923077, 131.51999999999998, 282.218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/kitti/augmented_test/images/2-wheeler-10_...</td>\n",
       "      <td>data/kitti/augmented_test/labels/2-wheeler-10_...</td>\n",
       "      <td>0</td>\n",
       "      <td>[295.84257602862255, 120.96, 476.8515205724508...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/kitti/augmented_test/images/2-wheeler-10_...</td>\n",
       "      <td>data/kitti/augmented_test/labels/2-wheeler-10_...</td>\n",
       "      <td>0</td>\n",
       "      <td>[484.63685152057246, 121.92, 615.0411449016101...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  \\\n",
       "0  data/kitti/augmented_test/images/2-wheeler-10_...   \n",
       "1  data/kitti/augmented_test/images/2-wheeler-10_...   \n",
       "2  data/kitti/augmented_test/images/2-wheeler-10_...   \n",
       "3  data/kitti/augmented_test/images/2-wheeler-10_...   \n",
       "4  data/kitti/augmented_test/images/2-wheeler-10_...   \n",
       "\n",
       "                                          label_path  class  \\\n",
       "0  data/kitti/augmented_test/labels/2-wheeler-10_...      1   \n",
       "1  data/kitti/augmented_test/labels/2-wheeler-10_...      1   \n",
       "2  data/kitti/augmented_test/labels/2-wheeler-10_...      0   \n",
       "3  data/kitti/augmented_test/labels/2-wheeler-10_...      0   \n",
       "4  data/kitti/augmented_test/labels/2-wheeler-10_...      0   \n",
       "\n",
       "                                              bboxes  \n",
       "0  [862.2254025044723, 150.72, 926.4543828264759,...  \n",
       "1  [871.9570661896244, 111.36, 917.6958855098391,...  \n",
       "2  [83.6923076923077, 131.51999999999998, 282.218...  \n",
       "3  [295.84257602862255, 120.96, 476.8515205724508...  \n",
       "4  [484.63685152057246, 121.92, 615.0411449016101...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['class'].unique())\n",
    "\n",
    "class_dict = {'2-wheeler': 0, \n",
    "              'pedestrian': 1, 'car': 2,\n",
    "              'dontcare': 3}\n",
    "\n",
    "df['class'] = df['class'].apply(lambda x:  class_dict[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "warming-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset Split\n",
    "X = df.image_path\n",
    "y = df[['bboxes', 'class']]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "imported-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(im_arr):\n",
    "    # Normalizes image with imagenet stats.\"\"\"\n",
    "    imagenet_stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n",
    "    return (im_arr - imagenet_stats[0])/imagenet_stats[1]\n",
    "\n",
    "class KittiDS(Dataset):\n",
    "    def __init__(self, paths, bboxes, y):\n",
    "        # self.transforms = transforms\n",
    "        self.paths = paths.values\n",
    "        self.bboxes = bboxes.values\n",
    "        self.y = y.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        y_class = self.y[idx]\n",
    "        y_bbox = self.bboxes[idx]\n",
    "        # x, y_bb = transformsXY(path, self.bb[idx], self.transforms)\n",
    "        x = cv2.cvtColor(cv2.imread(path).astype('float32'),\n",
    "                         cv2.COLOR_BGR2RGB)/255\n",
    "        x = normalize(x)\n",
    "        x = np.rollaxis(x, 2)\n",
    "        return x, y_bbox, y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ethical-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kitti = KittiDS(X_train, y_train['bboxes'], y_train['class'])\n",
    "val_kitti = KittiDS(X_val, y_val['bboxes'], y_val['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beginning-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch size\n",
    "batch_size = 8\n",
    "# For autobatching and parallelizing data-loading\n",
    "train_kitti_pt = DataLoader(train_kitti, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_kitti_pt = DataLoader(val_kitti, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "elect-picture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flexing my GPU ^_^ :  GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "# verify if GPU is being used with its name\n",
    "print(\"Flexing my GPU ^_^ : \", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deluxe-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "french-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "practical-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyKitti_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PyKitti_model, self).__init__()\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "        # children returns immediate child modules\n",
    "        layers = list(resnet.children())[:8]\n",
    "        self.features1 = nn.Sequential(*layers[:6])\n",
    "        self.features2 = nn.Sequential(*layers[6:])\n",
    "        # classification network\n",
    "        self.classifier = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n",
    "        # bbox regressor network\n",
    "        self.bbox = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features1(x)\n",
    "        # print(\"x shape after extracting features1: \", x.shape)\n",
    "        x = self.features2(x)\n",
    "        # print(\"x shape after extracting features2: \", x.shape)\n",
    "        x = F.relu(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
    "        # print(\"x shape before reshape: \", x.shape)\n",
    "        # reshape tensor\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # print(\"x shape: \", x.shape)\n",
    "        return self.classifier(x), self.bbox(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "noticed-coating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[475.3294, 356.2667, 593.3570, 538.6667],\n",
      "        [238.9167, 107.5000, 306.9167, 262.5000],\n",
      "        [418.3905, 107.6384, 509.8268, 238.8227],\n",
      "        [-37.5201, 245.0727,  63.3244, 441.9215],\n",
      "        [341.9729, 201.8462, 526.1122, 421.7436],\n",
      "        [140.4509,   4.1032, 187.5117,  75.2533],\n",
      "        [567.3592, 135.3357, 621.1430, 283.1699],\n",
      "        [215.1349, 193.6865, 275.6416, 340.7302]], dtype=torch.float64)\n",
      "tensor([[384.8333, 155.0000, 445.7500, 331.2500],\n",
      "        [632.4000, 107.5783, 727.6000, 171.3960],\n",
      "        [461.4461,  59.6189, 596.4436, 274.1977],\n",
      "        [571.7080, 157.4212, 811.8438, 287.9327],\n",
      "        [105.4264, 249.1034, 144.0827, 467.5862],\n",
      "        [357.5200,  91.1681, 496.2400, 290.8262],\n",
      "        [284.9947, 264.9870, 370.7125, 476.8564],\n",
      "        [358.5552, 211.5073, 391.9723, 273.2216]], dtype=torch.float64)\n",
      "tensor([[ 695.0284,  284.6897,  718.2222,  391.4483],\n",
      "        [ 424.6349,  222.4000,  608.5587,  409.6000],\n",
      "        [ 357.1631,  229.1518,  541.0870,  416.3518],\n",
      "        [ 873.8662,  115.2523,  919.6050,  207.4123],\n",
      "        [ 514.9867,  130.1333,  621.3689,  314.6667],\n",
      "        [ 525.2317,   62.4540,  571.4521,  161.2737],\n",
      "        [ 642.2282,  221.5385,  691.6828,  289.6410],\n",
      "        [ 950.0857,   94.9774, 1152.3539,  216.0706]], dtype=torch.float64)\n",
      "tensor([[  65.4896,   38.4000,  193.8491,  397.6000],\n",
      "        [ 443.9771,  193.3714,  534.1257,  412.8000],\n",
      "        [-175.6000,   99.3732, -132.0800,  183.2479],\n",
      "        [ 521.5367,  202.4467,  603.6103,  346.8570],\n",
      "        [ 910.3709,   70.0860, 1021.2028,  162.9242],\n",
      "        [ 152.8381,  143.3065,  203.6115,  236.1065],\n",
      "        [ 994.3494,   86.1346, 1052.1924,  222.3474],\n",
      "        [1036.6089,  178.0852, 1087.6089,  366.8352]], dtype=torch.float64)\n",
      "tensor([[ 316.9288,    8.0559,  350.5436,  105.2945],\n",
      "        [ 864.4752,  223.1645, 1086.7380,  302.0216],\n",
      "        [ 556.0295,   52.0434,  780.5799,  322.6689],\n",
      "        [ 588.3328,  300.0420,  864.4890,  396.2439],\n",
      "        [  47.9684,  230.4000,  285.0966,  376.5333],\n",
      "        [ 807.8400,   65.6410,  942.4800,  306.3248],\n",
      "        [  26.8919,   70.3596,   87.3986,  187.3621],\n",
      "        [ 557.6000,  119.4302,  701.7600,  198.7464]], dtype=torch.float64)\n",
      "tensor([[ 902.6672,  247.5948, 1003.5117,  444.4435],\n",
      "        [ 516.0966,  116.3623,  570.7207,  242.8514],\n",
      "        [ 276.9778,  103.5000,  366.1333,  448.5000],\n",
      "        [ 575.1043,  159.5605,  815.2402,  290.0720],\n",
      "        [ 643.8036,  294.6207,  655.7519,  340.1379],\n",
      "        [ 884.9207,  192.8205,  918.5919,  293.7436],\n",
      "        [ 458.6089,  163.0852,  539.3589,  363.0852],\n",
      "        [ 554.1912,  118.6236,  619.1689,  406.6236]], dtype=torch.float64)\n",
      "tensor([[268.3172, 221.5385, 317.7718, 289.6410],\n",
      "        [ 84.0371,  24.5073, 128.5767, 136.7664],\n",
      "        [-89.7500, 181.2500,  26.4167, 393.7500],\n",
      "        [264.5683, 321.6393, 332.9399, 375.7377],\n",
      "        [632.4000, 107.5783, 727.6000, 171.3960],\n",
      "        [853.1108, 116.0000, 946.5425, 353.6000],\n",
      "        [656.4548, 248.2759, 780.8579, 640.5517],\n",
      "        [624.5671,  80.6260, 762.9772, 323.0047]], dtype=torch.float64)\n",
      "tensor([[1.1348e+03, 8.8638e+01, 1.2023e+03, 2.3437e+02],\n",
      "        [2.5640e+02, 1.4112e+02, 3.3523e+02, 3.8016e+02],\n",
      "        [1.0775e+03, 2.1662e+02, 1.1259e+03, 3.7744e+02],\n",
      "        [4.5151e+02, 1.5557e+02, 6.0527e+02, 2.5637e+02],\n",
      "        [1.7325e+02, 2.3363e+02, 2.1744e+02, 3.0173e+02],\n",
      "        [5.0062e+02, 9.0141e+01, 5.5639e+02, 2.1433e+02],\n",
      "        [1.1802e+03, 8.0067e-01, 1.4596e+03, 2.6182e+02],\n",
      "        [7.4844e+02, 9.7500e+01, 9.3884e+02, 5.4000e+02]], dtype=torch.float64)\n",
      "tensor([[ 734.7034,  145.0123,  766.8179,  284.2123],\n",
      "        [ 276.0800,   82.9630,  452.8800,  301.7664],\n",
      "        [  46.8253,   88.6385,   95.7165,  218.8419],\n",
      "        [ 295.8426,  120.9600,  476.8515,  530.8800],\n",
      "        [1134.8253,   88.6385, 1202.3089,  234.3662],\n",
      "        [ 507.2394,  278.0107,  540.2730,  439.3901],\n",
      "        [ 857.3850,  252.4138,  936.8062,  509.7931],\n",
      "        [  33.5456,  150.7200,   97.7746,  319.6800]], dtype=torch.float64)\n",
      "tensor([[519.5255, 159.3352, 580.4422, 335.5852],\n",
      "        [296.5995, 283.0345, 333.8501, 400.5517],\n",
      "        [692.4655,  18.1828, 727.7611, 100.4008],\n",
      "        [570.0680, 200.0110, 641.4995, 355.7508],\n",
      "        [478.2799,  72.0911, 517.7774, 151.9374],\n",
      "        [216.2400, 113.9601, 243.4400, 177.7778],\n",
      "        [782.9586, 155.7333, 960.0000, 370.1333],\n",
      "        [163.3285, 332.8246, 246.5252, 509.1189]], dtype=torch.float64)\n",
      "tensor([[677.7818, 131.5200, 876.3077, 536.6400],\n",
      "        [284.7500,  67.5000, 467.5000, 452.5000],\n",
      "        [109.6020,  85.6714, 200.4914, 202.5688],\n",
      "        [161.7041,   0.0000, 306.5562,  53.3333],\n",
      "        [346.4889, 118.5000, 411.4667, 406.5000],\n",
      "        [421.7869, 109.7777, 513.2232, 240.9620],\n",
      "        [382.9848,  80.9987, 503.4856, 374.5987],\n",
      "        [768.4221,  93.8667, 809.5054, 200.1167]], dtype=torch.float64)\n",
      "tensor([[ 912.1369,  304.4143,  934.9275,  369.3323],\n",
      "        [ 449.6029,  151.6800,  603.3631,  252.4800],\n",
      "        [   8.5838,    3.2000,  138.4142,   88.5333],\n",
      "        [1092.0800,   99.3732, 1135.6000,  183.2479],\n",
      "        [ 261.4643,    4.1032,  308.5251,   95.8078],\n",
      "        [ 251.6000,  105.7550,  278.8000,  178.6895],\n",
      "        [ 745.6670,  305.3979,  776.3846,  377.2012],\n",
      "        [ 504.2998,  170.6667,  584.7732,  326.4000]], dtype=torch.float64)\n",
      "tensor([[ 735.1731,  270.6207,  772.4238,  457.6552],\n",
      "        [ 949.1621,  114.4000, 1035.6083,  344.0000],\n",
      "        [   0.0000,  125.2500,   37.7778,  370.5000],\n",
      "        [ 221.1265,  196.2086,  281.6332,  343.2522],\n",
      "        [ 536.9167,   83.7500,  630.4167,  342.5000],\n",
      "        [ 674.9034,  230.4000,  912.0316,  376.5333],\n",
      "        [ 666.2472,  101.6000,  737.8491,  334.4000],\n",
      "        [ 447.7106,  243.3103,  548.9199,  544.5517]], dtype=torch.float64)\n",
      "tensor([[853.1108, 116.0000, 946.5425, 353.6000],\n",
      "        [909.6889, 132.7500, 965.6000, 393.0000],\n",
      "        [474.4320,  64.7041, 540.9312, 185.7973],\n",
      "        [569.0895, 264.7694, 612.6658, 412.9073],\n",
      "        [226.2282, 216.6154, 262.0039, 286.3590],\n",
      "        [331.2347, 137.6000, 397.7594, 317.8667],\n",
      "        [703.5337, 303.9344, 736.2332, 372.7869],\n",
      "        [610.0833, 170.0000, 685.1667, 338.7500]], dtype=torch.float64)\n",
      "tensor([[ 565.3468,   95.6495,  627.3215,  226.8545],\n",
      "        [ 484.8939,  252.1878,  570.6117,  456.9421],\n",
      "        [ 128.4571,  224.2286,  145.5543,  263.3143],\n",
      "        [ 183.1155,  100.0834,  296.7273,  236.9975],\n",
      "        [1092.0800,   99.3732, 1135.6000,  183.2479],\n",
      "        [-227.9613,  216.6154, -159.5667,  375.7949],\n",
      "        [ 486.5460,  125.8123,  616.9503,  476.2123],\n",
      "        [ 851.4167,  171.2500,  927.9167,  346.2500]], dtype=torch.float64)\n",
      "tensor([[741.2859, 271.3901, 778.5366, 458.4245],\n",
      "        [719.4664, 200.1613, 789.2171, 332.1844],\n",
      "        [274.8333, 170.0000, 349.9167, 338.7500],\n",
      "        [364.4970, 273.0667, 453.5542, 428.8000],\n",
      "        [743.6962,  84.1315, 861.4481, 299.4679],\n",
      "        [492.7539, 222.1466, 565.0257, 407.9275],\n",
      "        [506.1998,  18.1828, 544.8568, 113.8402],\n",
      "        [817.6807, 176.2943, 889.1123, 340.7302]], dtype=torch.float64)\n",
      "tensor([[  94.3392,  101.6588,  140.4759,  214.3349],\n",
      "        [   7.1953,  325.3333,  251.8343,  452.2667],\n",
      "        [  13.7755,  159.3352,   49.1922,  266.8352],\n",
      "        [ 463.7600,   91.1681,  602.4800,  290.8262],\n",
      "        [ 876.5975,   90.1408,  933.0633,  207.8247],\n",
      "        [ 754.1092,  213.4505,  824.7003,  394.4881],\n",
      "        [1052.1924,   84.1315, 1131.3823,  248.8889],\n",
      "        [ 109.3572,   72.8816,  245.4972,  202.5330]], dtype=torch.float64)\n",
      "tensor([[ 40.6922, 156.8352,  91.6922, 274.3352],\n",
      "        [583.9266, 212.1930, 638.3266, 447.3930],\n",
      "        [796.9600, 113.9601, 835.0400, 176.8661],\n",
      "        [748.5029, 228.1026, 792.6963, 296.2051],\n",
      "        [546.4728, 242.3075, 763.5186, 381.5647],\n",
      "        [621.1657, 218.7429, 649.9200, 266.0571],\n",
      "        [801.1175, 224.8000, 917.6889, 372.8000],\n",
      "        [ 54.7331, 159.8429, 123.6435, 318.7449]], dtype=torch.float64)\n",
      "tensor([[ 195.0912,  141.1200,  227.2057,  280.3200],\n",
      "        [ 481.5324,    7.9056,  525.2317,   90.1235],\n",
      "        [ 120.1574,  128.6400,  178.5474,  184.3200],\n",
      "        [ 732.8889,  118.5000,  825.8222,  456.0000],\n",
      "        [ 607.4171,  293.1148,  672.8160,  427.8689],\n",
      "        [1408.9600,   96.6382, 1432.0800,  293.5613],\n",
      "        [ 246.2286,  113.0497,  300.8527,  255.3500],\n",
      "        [ 270.8960,  241.9105,  349.8908,  429.2726]], dtype=torch.float64)\n",
      "tensor([[ 624.5671,   80.6260,  762.9772,  323.0047],\n",
      "        [-454.4000,   84.7863, -368.7200,  294.4729],\n",
      "        [ 700.7500,  160.0000,  775.8333,  361.2500],\n",
      "        [ 659.1473,  113.0497,  713.7714,  255.3500],\n",
      "        [ 315.8123,  220.4216,  344.5666,  267.7359],\n",
      "        [   8.5127,  277.6360,   99.2727,  495.8298],\n",
      "        [ 713.4748,  197.6393,  783.2255,  329.6624],\n",
      "        [ 606.3402,  282.9763,  641.4823,  412.0797]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[871.9571, 111.3600, 917.6959, 203.5200],\n",
      "        [657.6914, 211.8857, 686.4457, 279.7714],\n",
      "        [  2.5211, 275.1139,  93.2812, 493.3077],\n",
      "        [111.5391, 249.8728, 150.1955, 468.3556],\n",
      "        [ 19.6571, 192.8000, 257.9810, 480.0000],\n",
      "        [100.0833, 158.7500, 170.9167, 338.7500],\n",
      "        [595.2791, 262.4650, 680.9969, 474.3343],\n",
      "        [799.5887,  85.1167, 836.4221, 206.3667]], dtype=torch.float64)\n",
      "tensor([[329.5833,  83.7500, 423.0833, 342.5000],\n",
      "        [675.3775, 151.6800, 721.1163, 312.9600],\n",
      "        [526.3543, 227.6571, 562.1029, 256.4571],\n",
      "        [176.2554, 122.6167, 262.6721, 355.1167],\n",
      "        [860.6105, 303.4307, 891.3282, 368.3487],\n",
      "        [357.2666,  10.4276, 414.4118,  84.7400],\n",
      "        [183.4793, 314.6667, 433.4832, 435.2000],\n",
      "        [ 48.0330, 231.5518, 164.6044, 379.5518]], dtype=torch.float64)\n",
      "tensor([[ 641.3119,  144.0318,  709.3819,  287.1226],\n",
      "        [ -58.5294,  116.2119,  -32.4779,  238.7483],\n",
      "        [  35.4167,  152.5000,   86.4167,  270.0000],\n",
      "        [ 835.7209,  221.1073,  866.0294,  282.8216],\n",
      "        [ 872.6679,  180.3518, 1039.3219,  321.9518],\n",
      "        [ 534.6069,  295.5618,  596.0422,  474.5782],\n",
      "        [ 121.6171,   51.9221,  282.3234,  125.2507],\n",
      "        [  51.5778,   98.8800,  323.0912,  367.6800]], dtype=torch.float64)\n",
      "tensor([[ 99.7029, 219.4286, 130.0114, 281.1429],\n",
      "        [500.6177,  90.1408, 556.3949, 214.3349],\n",
      "        [ 94.3392, 101.6588, 140.4759, 214.3349],\n",
      "        [556.3453,  58.8182, 780.8957, 329.4437],\n",
      "        [862.2254, 150.7200, 926.4544, 319.6800],\n",
      "        [508.1990,  37.6000, 674.1059, 412.0000],\n",
      "        [184.2440,   4.0000, 378.0931, 494.4000],\n",
      "        [124.1667,  81.2500, 161.0000, 202.5000]], dtype=torch.float64)\n",
      "tensor([[448.2554, 108.8667, 524.7554, 302.6167],\n",
      "        [310.1494, 258.6885, 416.1749, 526.2295],\n",
      "        [411.0801, 243.3103, 512.2894, 544.5517],\n",
      "        [820.9748, 300.4799, 853.6743, 364.4143],\n",
      "        [  8.5000, 155.0000,  43.9167, 262.5000],\n",
      "        [483.1485, 120.9600, 664.1574, 530.8800],\n",
      "        [ 65.4896,  38.4000, 193.8491, 397.6000],\n",
      "        [ 65.4896,  38.4000, 193.8491, 397.6000]], dtype=torch.float64)\n",
      "tensor([[4.6725e+02, 1.6602e+02, 5.2439e+02, 3.0595e+02],\n",
      "        [2.9775e+02, 1.2485e+02, 4.7876e+02, 5.3477e+02],\n",
      "        [4.2592e+02, 1.5875e+02, 5.0667e+02, 3.5875e+02],\n",
      "        [7.0817e+02, 3.2533e+02, 9.5280e+02, 4.5227e+02],\n",
      "        [7.1751e+02, 1.0240e+02, 8.7631e+02, 2.4640e+02],\n",
      "        [3.6234e+02, 1.9692e+02, 4.4441e+02, 3.4133e+02],\n",
      "        [1.0030e+03, 2.8121e+02, 1.2616e+03, 3.9355e+02],\n",
      "        [1.9665e+02, 7.9056e-01, 2.4203e+02, 6.4826e+01]], dtype=torch.float64)\n",
      "tensor([[ 653.4438,  100.2667,  800.4418,  216.5333],\n",
      "        [1049.9200,  110.3134, 1090.7200,  176.8661],\n",
      "        [ 731.6800,  126.7236,  752.0800,  165.0142],\n",
      "        [ 653.4438,    0.0000,  798.2959,   53.3333],\n",
      "        [  23.1938,  252.4138,  102.6150,  509.7931],\n",
      "        [ 652.6922,  166.8352,  702.2755,  311.8352],\n",
      "        [ 794.3589,  163.0852,  865.1922,  343.0852],\n",
      "        [ 915.3467,  132.8736,  971.2578,  393.1236]], dtype=torch.float64)\n",
      "tensor([[698.0255, 183.0852, 805.6922, 416.8352],\n",
      "        [484.6369, 121.9200, 615.0411, 472.3200],\n",
      "        [715.1555,  56.9201, 757.1740, 150.9964],\n",
      "        [487.5240,  10.4276, 531.2233,  92.6456],\n",
      "        [473.5010, 215.7949, 510.3288, 254.3590],\n",
      "        [143.2229, 229.0286, 336.7314, 291.4286],\n",
      "        [433.8878, 201.8462, 618.0271, 421.7436],\n",
      "        [ 94.9167, 163.7500, 178.5000, 323.7500]], dtype=torch.float64)\n",
      "tensor([[ 697.9961,  216.6154,  733.7718,  286.3590],\n",
      "        [ 918.0000,   85.6980, 1082.5600,  320.9117],\n",
      "        [ 344.8486,  132.8136,  398.6323,  280.6478],\n",
      "        [ 291.8501,  149.3333,  491.4241,  334.9333],\n",
      "        [-318.4000,  111.2251, -209.6000,  182.3362],\n",
      "        [ 657.4665,    1.5811,  704.5273,   93.2858],\n",
      "        [ 716.5600,  113.9601,  743.7600,  177.7778],\n",
      "        [ 653.0771,   91.0645,  700.1378,  170.9107]], dtype=torch.float64)\n",
      "tensor([[199.6072, 282.2069, 235.4522, 385.6552],\n",
      "        [  0.0000, 155.7333, 177.0414, 370.1333],\n",
      "        [ 46.8253,  88.6385,  95.7165, 218.8419],\n",
      "        [449.2998, 233.0256, 761.8104, 317.5385],\n",
      "        [327.7446,  82.2180, 439.5139, 218.1938],\n",
      "        [673.3511,  50.1333, 835.3422, 402.1333],\n",
      "        [400.9658, 224.6686, 473.2377, 410.4496],\n",
      "        [447.6667, 105.0000, 524.1667, 298.7500]], dtype=torch.float64)\n",
      "tensor([[833.6800, 117.6068, 864.9600, 183.2479],\n",
      "        [479.4478, 221.3185, 516.2756, 259.8826],\n",
      "        [421.1347,  20.7049, 459.7918, 116.3623],\n",
      "        [833.6800, 117.6068, 864.9600, 183.2479],\n",
      "        [769.6000,  99.3732, 809.0400, 181.4245],\n",
      "        [360.8589, 175.5852, 477.0255, 400.5852],\n",
      "        [707.0222, 307.3651, 739.7216, 376.2176],\n",
      "        [473.2377, 168.5391, 530.3829, 308.4677]], dtype=torch.float64)\n",
      "tensor([[ 134.1778,  118.5000,  227.1111,  456.0000],\n",
      "        [ 405.7908,  278.8405,  489.0258,  495.2340],\n",
      "        [1052.1924,   84.1315, 1131.3823,  248.8889],\n",
      "        [1125.5135,  222.1390, 1193.9081,  381.3185],\n",
      "        [ 100.1922,  168.0852,  183.7755,  328.0852],\n",
      "        [ 791.4167,  110.0000,  853.7500,  301.2500],\n",
      "        [ 415.1432,   18.1828,  453.8002,  113.8402],\n",
      "        [ 164.7127,  142.3003,  218.4964,  278.2761]], dtype=torch.float64)\n",
      "tensor([[ 142.5418,   68.1064,  355.3215,  390.6103],\n",
      "        [ 583.6667,  168.7500,  660.1667,  321.2500],\n",
      "        [ 735.1731,  270.6207,  772.4238,  457.6552],\n",
      "        [ 184.2440,    4.0000,  378.0931,  494.4000],\n",
      "        [  91.1200,  106.6667,  125.1200,  179.6011],\n",
      "        [ 945.9497,  214.9744, 1002.7698,  361.0256],\n",
      "        [ 108.0073,  289.1803,  162.5064,  480.0000],\n",
      "        [ 557.6000,  119.4302,  701.7600,  198.7464]], dtype=torch.float64)\n",
      "tensor([[1180.5419,    7.5755, 1459.8933,  268.5930],\n",
      "        [ 134.4593,    1.5811,  181.5201,   72.7313],\n",
      "        [ 640.4715,    4.1032,  667.3634,   76.8344],\n",
      "        [  46.8253,   88.6385,   95.7165,  218.8419],\n",
      "        [ 313.6378,  262.1192,  419.6633,  529.6602],\n",
      "        [ 634.4799,    1.5811,  661.3718,   74.3124],\n",
      "        [ 241.7778,  284.6897,  264.9716,  391.4483],\n",
      "        [ 403.6294,  229.3359,  439.3780,  258.1359]], dtype=torch.float64)\n",
      "tensor([[ 951.8965,  220.4980, 1008.7166,  366.5493],\n",
      "        [  17.5200,   65.6410,  152.1600,  306.3248],\n",
      "        [  29.3066,  253.1832,  108.7278,  510.5625],\n",
      "        [ 351.2750,    7.9056,  408.4202,   82.2180],\n",
      "        [ 643.8036,  294.6207,  655.7519,  340.1379],\n",
      "        [ 896.6756,  245.0727,  997.5201,  441.9215],\n",
      "        [ 998.4694,  118.7340, 1024.5209,  241.2703],\n",
      "        [ 839.5833,  113.7500,  931.6667,  323.7500]], dtype=torch.float64)\n",
      "tensor([[462.3129, 122.6867, 505.1718, 236.5270],\n",
      "        [593.8667, 103.5000, 683.0222, 448.5000],\n",
      "        [  4.8203,  94.6479,  44.7595, 203.8185],\n",
      "        [752.1318,  93.2858, 804.2348, 226.8899],\n",
      "        [732.8889, 118.5000, 825.8222, 456.0000],\n",
      "        [296.5995, 283.0345, 333.8501, 400.5517],\n",
      "        [207.9200, 126.7236, 228.3200, 165.0142],\n",
      "        [471.7600, 125.8120, 554.7200, 167.7493]], dtype=torch.float64)\n",
      "tensor([[170.7043, 144.8223, 224.4880, 280.7982],\n",
      "        [842.3481, 157.3209, 911.2585, 316.2229],\n",
      "        [538.6777,   4.7433, 573.9732,  75.1029],\n",
      "        [587.5281,  39.6782, 630.3871, 101.3417],\n",
      "        [765.5778,  10.2772, 900.0371, 152.5775],\n",
      "        [379.8395,  80.8000, 500.3403, 374.4000],\n",
      "        [624.5671,  80.6260, 762.9772, 323.0047],\n",
      "        [732.7943, 141.1200, 764.9088, 280.3200]], dtype=torch.float64)\n",
      "tensor([[179.1421, 248.2759, 303.5452, 640.5517],\n",
      "        [389.2622, 123.7333, 530.7022, 371.2000],\n",
      "        [721.1471,  59.4422, 763.1656, 153.5185],\n",
      "        [274.2640, 227.0621, 323.7186, 295.1647],\n",
      "        [155.7652,  93.2858, 207.8682, 226.8899],\n",
      "        [666.2472, 101.6000, 737.8491, 334.4000],\n",
      "        [626.1499, 283.0345, 663.4005, 400.5517],\n",
      "        [ 85.6015, 135.4123, 284.1274, 540.5323]], dtype=torch.float64)\n",
      "tensor([[ 540.7811,   73.6000,  591.2110,  165.3333],\n",
      "        [ 505.8710,  278.8405,  557.3974,  436.2176],\n",
      "        [ 821.5858,    3.2000,  951.4162,   88.5333],\n",
      "        [ 326.9428,    4.2667,  363.4241,  112.0000],\n",
      "        [ 241.7778,  284.6897,  264.9716,  391.4483],\n",
      "        [ 490.6694,  247.8502,  587.8123,  460.4216],\n",
      "        [1031.3333,  173.7500, 1082.3333,  362.5000],\n",
      "        [ 783.3617,  132.5323,  841.7517,  188.2123]], dtype=torch.float64)\n",
      "tensor([[  94.3392,  101.6588,  140.4759,  214.3349],\n",
      "        [ 733.4831,   78.4000,  857.4767,  366.4000],\n",
      "        [1006.4252,  283.3446, 1265.0330,  395.6922],\n",
      "        [ 327.4057,  210.5143,  381.8057,  445.7143],\n",
      "        [ 501.1266,  277.2414,  534.1602,  438.6207],\n",
      "        [ 118.2207,   49.7828,  278.9270,  123.1114],\n",
      "        [ 184.1667,  160.0000,  259.2500,  361.2500],\n",
      "        [ 232.2389,   18.1828,  267.5345,  100.4008]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[435.8333, 105.0000, 512.3333, 298.7500],\n",
      "        [507.1200,  82.9630, 683.9200, 301.7664],\n",
      "        [  0.0000, 125.2500,  37.7778, 370.5000],\n",
      "        [915.2727,  35.7254, 947.2068, 110.8284],\n",
      "        [853.1108, 116.0000, 946.5425, 353.6000],\n",
      "        [286.0178,  29.0489, 419.0161, 115.8324],\n",
      "        [298.6282,   1.5811, 325.5201,  74.3124],\n",
      "        [332.6233,  16.0000, 516.1026, 187.7333]], dtype=torch.float64)\n",
      "tensor([[356.6369, 151.6800, 510.3971, 252.4800],\n",
      "        [111.4958, 292.6110, 165.9948, 483.4307],\n",
      "        [389.2622, 123.7333, 530.7022, 371.2000],\n",
      "        [295.8426, 120.9600, 476.8515, 530.8800],\n",
      "        [232.4000, 107.5783, 327.6000, 171.3960],\n",
      "        [551.5798,   7.9056, 608.7250,  82.2180],\n",
      "        [636.9088,  98.8800, 908.4222, 367.6800],\n",
      "        [249.5492, 233.6000, 411.8857, 373.6000]], dtype=torch.float64)\n",
      "tensor([[ 463.7600,   91.1681,  602.4800,  290.8262],\n",
      "        [ 856.6922,  175.5852,  933.1922,  350.5852],\n",
      "        [ 435.6087,  166.0170,  492.7539,  305.9456],\n",
      "        [1119.5667,  216.6154, 1187.9613,  375.7949],\n",
      "        [ 389.3883,  252.1878,  475.1061,  456.9421],\n",
      "        [ 456.3213,  120.1647,  499.1802,  234.0049],\n",
      "        [ 368.7890,   73.6000,  419.2189,  165.3333],\n",
      "        [ 994.3494,   86.1346, 1052.1924,  222.3474]], dtype=torch.float64)\n",
      "tensor([[-121.0057,  221.4857,  101.2571,  300.3429],\n",
      "        [ 624.7728,  141.1200,  703.5993,  380.1600],\n",
      "        [ 873.5833,  152.5000,  924.5833,  270.0000],\n",
      "        [ 590.6286,  240.0000,  714.1079,  311.2000],\n",
      "        [ 913.4830,  113.0497,  979.0319,  243.4916],\n",
      "        [ 979.9389,  188.3672, 1238.5467,  296.0056],\n",
      "        [ 994.3494,   86.1346, 1052.1924,  222.3474],\n",
      "        [ 520.4861,   82.2180,  632.2554,  218.1938]], dtype=torch.float64)\n",
      "tensor([[267.4794, 202.4000, 473.8540, 451.2000],\n",
      "        [684.3584, 193.6865, 744.8651, 340.7302],\n",
      "        [508.1990,  37.6000, 674.1059, 412.0000],\n",
      "        [516.7137, 130.5065, 623.0959, 315.0398],\n",
      "        [247.8906, 285.4590, 271.0844, 392.2176],\n",
      "        [738.5467, 118.6236, 831.4801, 456.1236],\n",
      "        [310.9372,   5.5339, 344.5520, 102.7724],\n",
      "        [817.4863, 297.0492, 850.1858, 360.9836]], dtype=torch.float64)\n",
      "tensor([[1.1730e+02, 1.4195e+02, 3.3619e+02, 3.0206e+02],\n",
      "        [2.9197e+02, 7.4116e+01, 3.6978e+02, 2.9296e+02],\n",
      "        [6.4742e+02, 1.6250e+02, 6.9700e+02, 3.0750e+02],\n",
      "        [4.6113e+02, 5.2844e+01, 5.9613e+02, 2.6742e+02],\n",
      "        [1.3287e+03, 8.4786e+01, 1.4144e+03, 2.9447e+02],\n",
      "        [7.1797e+02, 7.9056e-01, 7.6335e+02, 6.4826e+01],\n",
      "        [3.7984e+02, 8.0800e+01, 5.0034e+02, 3.7440e+02],\n",
      "        [6.1011e+02, 2.4191e+02, 6.8910e+02, 4.2927e+02]], dtype=torch.float64)\n",
      "tensor([[ 692.7500,  178.7500,  800.4167,  412.5000],\n",
      "        [ 453.8234,  244.0797,  555.0327,  545.3211],\n",
      "        [1134.8253,   88.6385, 1202.3089,  234.3662],\n",
      "        [ 778.4799,    1.5811,  825.5407,   72.7313],\n",
      "        [ 176.7745,  197.6393,  246.5252,  329.6624],\n",
      "        [ 280.1089,  174.3352,  355.1922,  343.0852],\n",
      "        [ 175.6667,  118.7500,  262.0833,  351.2500],\n",
      "        [ 302.7123,  283.8039,  339.9629,  401.3211]], dtype=torch.float64)\n",
      "tensor([[ 375.2268,  170.6667,  455.7002,  326.4000],\n",
      "        [  18.7848,   33.2034,   50.7188,  108.3063],\n",
      "        [ 781.4526,  128.6400,  839.8426,  184.3200],\n",
      "        [-130.7200,  110.3134,  -89.9200,  176.8661],\n",
      "        [ 983.3352,  190.5065, 1241.9431,  298.1449],\n",
      "        [ 402.3024,  275.4098,  485.5373,  491.8033],\n",
      "        [ 938.8589,  185.5852, 1055.0255,  398.0852],\n",
      "        [ 124.9600,  113.9601,  163.0400,  176.8661]], dtype=torch.float64)\n",
      "tensor([[ 952.3074,  114.5987, 1038.7536,  344.1987],\n",
      "        [ 347.9197,  207.3698,  532.0590,  427.2672],\n",
      "        [ 291.9696,   74.1158,  369.7823,  292.9577],\n",
      "        [ 324.6305,  282.2069,  359.7726,  411.3103],\n",
      "        [ 713.4748,  332.8246,  796.6715,  509.1189],\n",
      "        [ 715.5126,  203.4872, 1046.9632,  310.9744],\n",
      "        [-122.3333,  173.7500,  -71.3333,  362.5000],\n",
      "        [ 720.4943,   70.3596,  856.6344,  200.0110]], dtype=torch.float64)\n",
      "tensor([[ 825.3998,    3.4848,  933.4609,   79.5044],\n",
      "        [ 565.3468,   95.6495,  627.3215,  226.8545],\n",
      "        [ 856.2560,  116.1987,  949.6878,  353.7987],\n",
      "        [-122.5600,   85.6980,   42.0000,  320.9117],\n",
      "        [ 796.9600,  113.9601,  835.0400,  176.8661],\n",
      "        [ 815.9173,  249.1034,  854.5736,  467.5862],\n",
      "        [  81.5464,   28.8000,  219.9606,  101.3333],\n",
      "        [ 600.2274,  282.2069,  635.3695,  411.3103]], dtype=torch.float64)\n",
      "tensor([[150.9600,  99.3732, 190.4000, 181.4245],\n",
      "        [399.6800, 231.0857, 429.9886, 253.7143],\n",
      "        [159.5833, 178.7500, 267.2500, 412.5000],\n",
      "        [593.8667, 103.5000, 683.0222, 448.5000],\n",
      "        [255.4727,   1.5811, 302.5335,  93.2858],\n",
      "        [ 32.0833, 171.2500, 108.5833, 346.2500],\n",
      "        [631.6686,   0.0000, 777.5937, 102.4000],\n",
      "        [790.2571, 300.4799, 818.9930, 385.0700]], dtype=torch.float64)\n",
      "tensor([[   5.6578,  125.3736,   43.4356,  370.6236],\n",
      "        [ 537.5054,   87.6167,  631.0054,  346.3667],\n",
      "        [ 933.5833,  181.2500, 1049.7500,  393.7500],\n",
      "        [ 610.9056,  296.5454,  676.3045,  431.2995],\n",
      "        [ 876.5975,   90.1408,  933.0633,  207.8247],\n",
      "        [ 103.3656,   70.3596,  239.5057,  200.0110],\n",
      "        [ 581.5366,   71.9407,  635.3203,  180.2470],\n",
      "        [ 284.4384,  277.1832,  311.1464,  399.6659]], dtype=torch.float64)\n",
      "tensor([[ 374.6025,   79.6244,  506.1266,  363.0673],\n",
      "        [ 335.6045,   37.1562,  378.4634,   98.8197],\n",
      "        [ 669.3925,  101.7987,  740.9944,  334.5987],\n",
      "        [ 562.9767,  264.0000,  606.5530,  412.1379],\n",
      "        [ 374.6025,   79.6244,  506.1266,  363.0673],\n",
      "        [1328.7200,   84.7863, 1414.4000,  294.4729],\n",
      "        [ 831.4233,   24.5073,  875.9629,  136.7664],\n",
      "        [ 862.2254,  150.7200,  926.4544,  319.6800]], dtype=torch.float64)\n",
      "tensor([[  28.9221,  117.6167,  121.0054,  327.6167],\n",
      "        [ 662.5676,  249.0452,  786.9707,  641.3211],\n",
      "        [ 866.9460,  173.6000, 1033.6000,  315.2000],\n",
      "        [ 514.9867,  130.1333,  621.3689,  314.6667],\n",
      "        [ 909.2812,   33.2034,  941.2152,  108.3063],\n",
      "        [ 543.0764,  240.1682,  760.1222,  379.4254],\n",
      "        [ 548.5333,  118.5000,  613.5111,  406.5000],\n",
      "        [ 183.4313,  106.8583,  297.0431,  243.7724]], dtype=torch.float64)\n",
      "tensor([[ 46.0969, 265.0700, 108.5231, 477.5290],\n",
      "        [781.5000, 163.7500, 865.0833, 323.7500],\n",
      "        [ 14.0503, 219.0769,  75.0793, 368.4103],\n",
      "        [626.6820, 145.0123, 705.5084, 384.0523],\n",
      "        [447.7106, 243.3103, 548.9199, 544.5517],\n",
      "        [615.4480,   5.5339, 649.0628, 102.7724],\n",
      "        [742.1785, 301.9672, 772.8962, 373.7705],\n",
      "        [434.7683,   7.9056, 478.4676,  90.1235]], dtype=torch.float64)\n",
      "tensor([[ 28.3333, 113.7500, 120.4167, 323.7500],\n",
      "        [  3.3964, 242.9802, 173.3386, 397.7104],\n",
      "        [526.5168, 314.6667, 776.5207, 435.2000],\n",
      "        [ 32.8834,  72.8816,  93.3901, 189.8841],\n",
      "        [149.3841, 216.0000, 312.5841, 415.2000],\n",
      "        [263.0000, 162.5000, 312.5833, 307.5000],\n",
      "        [379.8395,  80.8000, 500.3403, 374.4000],\n",
      "        [733.4831,  78.4000, 857.4767, 366.4000]], dtype=torch.float64)\n",
      "tensor([[  83.6923,  102.4000,  242.4931,  246.4000],\n",
      "        [ 949.1621,  114.4000, 1035.6083,  344.0000],\n",
      "        [ 743.6962,   84.1315,  861.4481,  299.4679],\n",
      "        [ 285.3387,   71.3667,  468.0887,  456.3667],\n",
      "        [ 109.9178,   92.4462,  200.8073,  209.3437],\n",
      "        [ 377.9200,  246.1714,  475.0629,  458.7429],\n",
      "        [ 120.6935,  144.0874,  339.5865,  304.1996],\n",
      "        [ 511.3443,   37.7987,  677.2512,  412.1987]], dtype=torch.float64)\n",
      "tensor([[353.4470, 264.0000, 397.0233, 412.1379],\n",
      "        [106.2500, 110.0000, 168.5833, 301.2500],\n",
      "        [890.8675, 224.6006, 951.8965, 373.9339],\n",
      "        [142.5418,  68.1064, 355.3215, 390.6103],\n",
      "        [202.6383,   3.3126, 248.0184,  67.3477],\n",
      "        [548.5333, 118.5000, 613.5111, 406.5000],\n",
      "        [531.2233,  64.9761, 577.4437, 163.7957],\n",
      "        [654.9664, 276.4138, 681.6744, 398.8966]], dtype=torch.float64)\n",
      "tensor([[ 719.4664,  335.3466,  802.6631,  511.6409],\n",
      "        [ 151.1111,  142.9333,  201.8844,  235.7333],\n",
      "        [1083.4246,  222.1390, 1131.8269,  382.9596],\n",
      "        [ 645.3209,  195.0502,  723.0352,  416.5359],\n",
      "        [ -42.7698,  214.9744,   14.0503,  361.0256],\n",
      "        [ 484.6369,  121.9200,  615.0411,  472.3200],\n",
      "        [ 596.5759,    4.2667,  633.0572,  112.0000],\n",
      "        [  42.3041,  111.3600,   88.0429,  203.5200]], dtype=torch.float64)\n",
      "tensor([[624.7728, 141.1200, 703.5993, 380.1600],\n",
      "        [490.8855, 254.7098, 576.6033, 459.4641],\n",
      "        [919.4746, 115.5717, 985.0235, 246.0137],\n",
      "        [ 70.8877, 176.2943, 142.3193, 340.7302],\n",
      "        [581.5366,  37.1562, 624.3955,  98.8197],\n",
      "        [823.6723, 178.8163, 895.1038, 343.2522],\n",
      "        [531.1184, 292.1311, 592.5537, 471.1475],\n",
      "        [697.9167, 118.7500, 784.3333, 351.2500]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 741.5036,  142.3003,  795.2873,  278.2761],\n",
      "        [ 304.2481,  294.6207,  316.1964,  340.1379],\n",
      "        [ 565.3468,   95.6495,  627.3215,  226.8545],\n",
      "        [ 135.2997,  213.4505,  205.8908,  394.4881],\n",
      "        [  68.6349,   38.5987,  196.9944,  397.7987],\n",
      "        [ 992.4779,  116.2119, 1018.5294,  238.7483],\n",
      "        [ 374.6025,   79.6244,  506.1266,  363.0673],\n",
      "        [ 184.2440,    4.0000,  378.0931,  494.4000]], dtype=torch.float64)\n",
      "tensor([[ 949.1621,  114.4000, 1035.6083,  344.0000],\n",
      "        [ 251.6000,  105.7550,  278.8000,  178.6895],\n",
      "        [ 909.6889,  132.7500,  965.6000,  393.0000],\n",
      "        [ 183.1155,  100.0834,  296.7273,  236.9975],\n",
      "        [  21.1556,   97.5000,  211.5556,  540.0000],\n",
      "        [1408.9600,   96.6382, 1432.0800,  293.5613],\n",
      "        [ 834.8800,  106.6667,  868.8800,  179.6011],\n",
      "        [ 694.2170,  141.8667,  860.5286,  226.1333]], dtype=torch.float64)\n",
      "tensor([[ 544.6692,    7.2654,  579.9648,   77.6250],\n",
      "        [ 721.4594,  209.0108, 1052.9101,  316.4980],\n",
      "        [ 653.0833,  107.5000,  721.0833,  262.5000],\n",
      "        [ 198.1896,  233.0256,  510.7002,  317.5385],\n",
      "        [ -86.9632,  203.4872,  244.4874,  310.9744],\n",
      "        [ 649.9164,  295.3901,  661.8647,  340.9073],\n",
      "        [ 822.0034,    1.3455,  930.0645,   77.3651],\n",
      "        [ 255.2711,  240.3518,  417.6076,  380.3518]], dtype=torch.float64)\n",
      "tensor([[ 501.1266,  277.2414,  534.1602,  438.6207],\n",
      "        [ -19.0319,  113.0497,   46.5170,  243.4916],\n",
      "        [ 946.6893,   92.8381, 1148.9576,  213.9313],\n",
      "        [ 472.2884,   69.5690,  511.7858,  149.4153],\n",
      "        [ 258.2400,  119.4302,  402.4000,  198.7464],\n",
      "        [ 460.8198,  120.1647,  503.6787,  234.0049],\n",
      "        [ 676.7337,   67.2000,  804.4181,  201.6000],\n",
      "        [ 151.0833,   90.0000,  192.1667,  196.2500]], dtype=torch.float64)\n",
      "tensor([[  -5.6000,  132.7500,   50.3111,  393.0000],\n",
      "        [ 681.2000,  105.7550,  708.4000,  178.6895],\n",
      "        [ 468.5759,  149.3333,  668.1499,  334.9333],\n",
      "        [ 964.0506,   87.6369, 1005.3671,  206.3224],\n",
      "        [ 449.6712,  215.7949,  486.4990,  254.3590],\n",
      "        [ 767.8333,   90.0000,  808.9167,  196.2500],\n",
      "        [ 151.1111,  142.9333,  201.8844,  235.7333],\n",
      "        [  42.3111,  224.8000,  158.8825,  372.8000]], dtype=torch.float64)\n",
      "tensor([[ 448.2142,   69.5690,  487.7116,  149.4153],\n",
      "        [ 922.2222,  125.2500,  960.0000,  370.5000],\n",
      "        [  26.8134,   97.6236,  217.2134,  540.1236],\n",
      "        [ 871.8778,   37.6734, 1035.3548,  147.3301],\n",
      "        [ 453.3333,  158.7500,  534.0833,  358.7500],\n",
      "        [ 906.9745,   67.9467, 1017.8065,  160.7849],\n",
      "        [ 202.8260,   56.9201,  244.8445,  150.9964],\n",
      "        [  95.0400,  117.6068,  126.3200,  183.2479]], dtype=torch.float64)\n",
      "tensor([[ 673.3511,   50.1333,  835.3422,  402.1333],\n",
      "        [ 964.0506,   87.6369, 1005.3671,  206.3224],\n",
      "        [  42.6084,  261.6393,  105.0346,  474.0984],\n",
      "        [ 276.0800,   82.9630,  452.8800,  301.7664],\n",
      "        [ 405.2800,  125.8120,  488.2400,  167.7493],\n",
      "        [ 864.1346,  154.6123,  928.3635,  323.5723],\n",
      "        [ 252.2202,  115.5717,  306.8443,  257.8720],\n",
      "        [ 238.8837,  151.6800,  284.6225,  312.9600]], dtype=torch.float64)\n",
      "tensor([[506.4458, 273.0667, 595.5030, 428.8000],\n",
      "        [344.9589, 121.9200, 475.3631, 472.3200],\n",
      "        [187.3893,   4.1987, 381.2384, 494.5987],\n",
      "        [187.5762, 270.6207, 224.8269, 457.6552],\n",
      "        [142.5418,  68.1064, 355.3215, 390.6103],\n",
      "        [908.6485, 300.9836, 931.4390, 365.9016],\n",
      "        [333.7362,  84.7400, 445.5055, 220.7158],\n",
      "        [ 91.1200, 106.6667, 125.1200, 179.6011]], dtype=torch.float64)\n",
      "tensor([[733.4831,  78.4000, 857.4767, 366.4000],\n",
      "        [741.8182,  29.6247, 878.1523, 192.9608],\n",
      "        [771.5693,  12.7993, 906.0287, 155.0996],\n",
      "        [884.9207, 219.0769, 945.9497, 368.4103],\n",
      "        [561.3677, 132.8136, 615.1514, 280.6478],\n",
      "        [635.3203, 141.5097, 703.3903, 284.6006],\n",
      "        [732.7943, 141.1200, 764.9088, 280.3200],\n",
      "        [ 54.4000, 110.3134,  93.8400, 176.8661]], dtype=torch.float64)\n",
      "tensor([[562.9767, 264.0000, 606.5530, 412.1379],\n",
      "        [461.1302,  52.8440, 596.1278, 267.4229],\n",
      "        [786.7687, 297.0492, 815.5046, 381.6393],\n",
      "        [687.7791,  50.1333, 834.7771, 135.4667],\n",
      "        [129.0059,  84.2136, 309.1077, 166.9606],\n",
      "        [871.9571, 111.3600, 917.6959, 203.5200],\n",
      "        [ 27.6444, 105.0000, 153.8222, 501.7500],\n",
      "        [548.1143, 233.6000, 710.4508, 373.6000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for x, y_bbox, y_class in train_kitti_pt:\n",
    "    print(y_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fiscal-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "def train(model, optimizer, train_kitti_pt, val_kitti_pt, epochs=10,C=1000):\n",
    "    for i in range(epochs):\n",
    "        # enables model training, grad compute\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        correct = 0\n",
    "        for x, y_bbox, y_class in train_kitti_pt:\n",
    "            batch = y_class.shape[0]\n",
    "            # fp32 precision\n",
    "            # x = x.cuda().float()\n",
    "            x = x.float().to(device)\n",
    "            # print(\"x shape: \", x.shape)\n",
    "            # y_class = y_class.cuda()\n",
    "            y_class = y_class.long().to(device)\n",
    "            # print(\"y_class: \", y_class, 'y_class shape: ', y_class.shape)\n",
    "            # fp32 precision \n",
    "            # y_bbox = y_bbox.cuda().float()\n",
    "            y_bbox = y_bbox.float().to(device, dtype=float)\n",
    "            # print(\"y_bbox: \", y_bbox, \"\\ny_bbox shape\", y_bbox.shape)\n",
    "            out_class, out_bbox = model.forward(x)\n",
    "            # print(\"out_bbox: \", out_bbox, \"\\nout_bbox shape\", out_bbox.shape)\n",
    "            # print(\"out_class: \", out_class, '\\nout_class shape: ', out_class.shape)\n",
    "            # compute classification loss: torch.max(outputs, 1)[1], torch.max(labels, 1)[1]\n",
    "            clf_loss = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "            # compute L1 loss\n",
    "            bbox_reg_loss = F.l1_loss(out_bbox, y_bbox, reduction=\"none\").sum(1)\n",
    "            bbox_reg_loss = bbox_reg_loss.sum()\n",
    "            # computing total loss\n",
    "            loss = clf_loss + bbox_reg_loss/C\n",
    "            # set gradients to 0\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total += batch\n",
    "            sum_loss += loss.item()\n",
    "            _, pred = torch.max(out_class, 1)\n",
    "            correct += pred.eq(y_class).sum().item()\n",
    "        train_loss = sum_loss/total\n",
    "        train_acc = correct/total\n",
    "        val_loss, val_acc = val_metrics(model, val_kitti_pt, C)\n",
    "        print(\"Epoch: \",i+1,\"/\",epochs,\"\\n----------------------------\")\n",
    "        print(\"Train_loss: %.3f, Train_acc: %.3f,\\nVal_loss: %.3f, Val_acc: %.3f\" % \n",
    "              (train_loss, train_acc,val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "rough-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute validation metrics\n",
    "def val_metrics(model, val_kitti_pt, C=1000):\n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    # pair .eval() with no_grad\n",
    "    # turn off grad computation\n",
    "    with torch.no_grad():\n",
    "        for x, y_bbox, y_class in val_kitti_pt:\n",
    "            batch = y_class.shape[0]\n",
    "            x = x.float().to(device)\n",
    "            y_class = y_class.long().to(device)\n",
    "            y_bbox = y_bbox.float().to(device, dtype=float)\n",
    "            out_class, out_bbox = model.forward(x)\n",
    "            clf_loss = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "            bbox_reg_loss = F.l1_loss(out_bbox, y_bbox, reduction=\"none\").sum(1)\n",
    "            bbox_reg_loss = bbox_reg_loss.sum()\n",
    "            loss = clf_loss + bbox_reg_loss/C\n",
    "            _, pred = torch.max(out_class, 1)\n",
    "            correct += pred.eq(y_class).sum().item()\n",
    "            sum_loss += loss.item()\n",
    "            total += batch\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "attractive-spider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers of resnet to be used: \n",
      " [Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (2): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (2): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (3): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (2): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (3): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (4): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (5): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (2): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "model1 = PyKitti_model().to(device)\n",
    "parameters = filter(lambda p: p.requires_grad, model1.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "immediate-bennett",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 / 10 \n",
      "----------------------------\n",
      "Train_loss: 2.904, Train_acc: 0.468,\n",
      "Val_loss: 23.700, Val_acc: 0.478\n",
      "Epoch:  1 / 10 \n",
      "----------------------------\n",
      "Train_loss: 2.008, Train_acc: 0.589,\n",
      "Val_loss: 1.830, Val_acc: 0.574\n",
      "Epoch:  2 / 10 \n",
      "----------------------------\n",
      "Train_loss: 1.541, Train_acc: 0.680,\n",
      "Val_loss: 1.905, Val_acc: 0.522\n",
      "Epoch:  3 / 10 \n",
      "----------------------------\n",
      "Train_loss: 1.531, Train_acc: 0.680,\n",
      "Val_loss: 2.652, Val_acc: 0.640\n",
      "Epoch:  4 / 10 \n",
      "----------------------------\n",
      "Train_loss: 1.461, Train_acc: 0.713,\n",
      "Val_loss: 1.602, Val_acc: 0.684\n",
      "Epoch:  5 / 10 \n",
      "----------------------------\n",
      "Train_loss: 1.419, Train_acc: 0.745,\n",
      "Val_loss: 3.568, Val_acc: 0.640\n",
      "Epoch:  6 / 10 \n",
      "----------------------------\n",
      "Train_loss: 1.474, Train_acc: 0.709,\n",
      "Val_loss: 1.417, Val_acc: 0.721\n",
      "Epoch:  7 / 10 \n",
      "----------------------------\n",
      "Train_loss: 1.503, Train_acc: 0.718,\n",
      "Val_loss: 1.765, Val_acc: 0.581\n",
      "Epoch:  8 / 10 \n",
      "----------------------------\n",
      "Train_loss: 1.407, Train_acc: 0.734,\n",
      "Val_loss: 1.421, Val_acc: 0.757\n",
      "Epoch:  9 / 10 \n",
      "----------------------------\n",
      "Train_loss: 1.461, Train_acc: 0.736,\n",
      "Val_loss: 1.986, Val_acc: 0.559\n",
      "CPU times: user 4min 15s, sys: 1min 40s, total: 5min 55s\n",
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(model1, optimizer, train_kitti_pt, val_kitti_pt, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "innovative-rwanda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun  8 17:19:27 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 3080    Off  | 00000000:09:00.0  On |                  N/A |\r\n",
      "| 38%   65C    P2   131W / 320W |   5727MiB / 10014MiB |     21%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-tackle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
